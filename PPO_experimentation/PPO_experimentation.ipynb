{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Candidate name: Sneha Santha Prabakar**\n",
        "\n",
        "**Week 6: PPO Experimentation**"
      ],
      "metadata": {
        "id": "eJ1cPJ3V99X2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An AI agent learns to balance a simulated pole on a cart by moving the cart left or right.\n",
        "\n",
        "The agent is rewarded for each step it takes to keep the pole upright for as long as possible.\n",
        "\n",
        "The exercise ends when the pole falls, or the cart moves too far from the centre point.\n",
        "\n",
        "- Goal: Keep the pole balanced upright by moving the cart left or right\n",
        "  - So every **action** the agent takes is trying to:\n",
        "    - Prevent the pole from tipping too far\n",
        "    - Keep the cart going off the track\n",
        "  - The agent gets **+1 reward** for every time step the pole remains balanced and the cart is within bounds\n",
        "- Number of steps per epoch: 4,000\n",
        "- Episode: One try/run of the agent\n",
        "  - Begins when the agen starts from the beginning of the environment\n",
        "  - Ends when:\n",
        "    - The poll falls - indicated if the pole's angle exceeds a certain threshold; e.g. +- 12 degrees from vertical)\n",
        "    - The cart moves too far from the center\n",
        "    - It reaches the max steps (4,000) - Then it did perfectly!\n",
        "  - Here, One episode = one attempt to balance the pole for as long as possible\n",
        "- Epoch: One training cycle\n",
        "  - How often the agent updates its neural network using the data it just collected\n",
        "  - During each epoch:\n",
        "    - The agent plays many episodes (to collect experience), then it calculates **advantage** (how good certain actions were) and then updates policy.\n",
        "    - Then it uses that data to update its policy (learning step)\n",
        "    - The number of episodes per epoch is variable - it depends on how long the agent survives in each episode. In each epoch, the agent collects 4,000 time steps worth of experience.\n",
        "      - So it can take 20 episodes (if each episode lasts approximately 200 steps), or even 1 episode (if it lasts the full 4000 steps).\n",
        "  - Here, the number of epochs is set by the developer (without any early stopping condition)\n",
        "- Mean return = Average reward per episode (higher=better)\n",
        "- Mean length = Average number of steps survived per episode\n",
        "- Here, the reward = number of steps survived\n",
        "\n",
        "\n",
        "General ways to evaluate the performance of the model (after hyperparameter tuning):\n",
        "- Higher mean return early --> model learns faster\n",
        "- Reaches max length (4,000) quickly --> model has mastered the task\n",
        "- Stable performance after reaching max --> reliable policy\n",
        "- Less variance in episode returns --> Consistent learning\n",
        "\n",
        "Hence, the ways to evaluate long-term stability are:\n",
        "1. Performance over time: Plot the mean return and mean length over all epochs\n",
        "  - If if plateaus at a high value and stays there - good model\n",
        "  - If it fluctuates or drops after a few good epochs - bad (over-fitting)\n",
        "2. [...]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "35NnAqc8-LD7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "DK6ps8LFMdlg"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Rt2MnxdJqdr"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"KERAS_BACKEND\"] = \"tensorflow\"\n",
        "\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import gymnasium as gym\n",
        "import scipy.signal\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions and Class"
      ],
      "metadata": {
        "id": "WM8cehgwMgAz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def discounted_cumulative_sums(x, discount):\n",
        "    # Discounted cumulative sums of vectors for computing rewards-to-go and advantage estimates\n",
        "    return scipy.signal.lfilter([1], [1, float(-discount)], x[::-1], axis=0)[::-1]\n",
        "\n",
        "\n",
        "class Buffer:\n",
        "    # Buffer for storing trajectories\n",
        "    def __init__(self, observation_dimensions, size, gamma=0.99, lam=0.95):\n",
        "        # Buffer initialization\n",
        "        self.observation_buffer = np.zeros(\n",
        "            (size, observation_dimensions), dtype=np.float32\n",
        "        )\n",
        "        self.action_buffer = np.zeros(size, dtype=np.int32)\n",
        "        self.advantage_buffer = np.zeros(size, dtype=np.float32)\n",
        "        self.reward_buffer = np.zeros(size, dtype=np.float32)\n",
        "        self.return_buffer = np.zeros(size, dtype=np.float32)\n",
        "        self.value_buffer = np.zeros(size, dtype=np.float32)\n",
        "        self.logprobability_buffer = np.zeros(size, dtype=np.float32)\n",
        "        self.gamma, self.lam = gamma, lam\n",
        "        self.pointer, self.trajectory_start_index = 0, 0\n",
        "\n",
        "    def store(self, observation, action, reward, value, logprobability):\n",
        "        # Append one step of agent-environment interaction\n",
        "        self.observation_buffer[self.pointer] = observation\n",
        "        self.action_buffer[self.pointer] = action\n",
        "        self.reward_buffer[self.pointer] = reward\n",
        "        self.value_buffer[self.pointer] = value\n",
        "        self.logprobability_buffer[self.pointer] = logprobability\n",
        "        self.pointer += 1\n",
        "\n",
        "    def finish_trajectory(self, last_value=0):\n",
        "        # Finish the trajectory by computing advantage estimates and rewards-to-go\n",
        "        path_slice = slice(self.trajectory_start_index, self.pointer)\n",
        "        rewards = np.append(self.reward_buffer[path_slice], last_value)\n",
        "        values = np.append(self.value_buffer[path_slice], last_value)\n",
        "\n",
        "        deltas = rewards[:-1] + self.gamma * values[1:] - values[:-1]\n",
        "\n",
        "        self.advantage_buffer[path_slice] = discounted_cumulative_sums(\n",
        "            deltas, self.gamma * self.lam\n",
        "        )\n",
        "        self.return_buffer[path_slice] = discounted_cumulative_sums(\n",
        "            rewards, self.gamma\n",
        "        )[:-1]\n",
        "\n",
        "        self.trajectory_start_index = self.pointer\n",
        "\n",
        "    def get(self):\n",
        "        # Get all data of the buffer and normalize the advantages\n",
        "        self.pointer, self.trajectory_start_index = 0, 0\n",
        "        advantage_mean, advantage_std = (\n",
        "            np.mean(self.advantage_buffer),\n",
        "            np.std(self.advantage_buffer),\n",
        "        )\n",
        "        self.advantage_buffer = (self.advantage_buffer - advantage_mean) / advantage_std\n",
        "        return (\n",
        "            self.observation_buffer,\n",
        "            self.action_buffer,\n",
        "            self.advantage_buffer,\n",
        "            self.return_buffer,\n",
        "            self.logprobability_buffer,\n",
        "        )\n",
        "\n",
        "\n",
        "def mlp(x, sizes, activation=keras.activations.tanh, output_activation=None):\n",
        "    # Build a feedforward neural network\n",
        "    for size in sizes[:-1]:\n",
        "        x = layers.Dense(units=size, activation=activation)(x)\n",
        "    return layers.Dense(units=sizes[-1], activation=output_activation)(x)\n",
        "\n",
        "\n",
        "def logprobabilities(logits, a, num_actions):\n",
        "    # Compute the log-probabilities of taking actions a by using the logits (i.e. the output of the actor)\n",
        "    logprobabilities_all = keras.ops.log_softmax(logits)\n",
        "    logprobability = keras.ops.sum(\n",
        "        keras.ops.one_hot(a, tf.cast(num_actions, tf.int32)) * logprobabilities_all, axis=1\n",
        "    )\n",
        "    return logprobability\n",
        "\n",
        "\n",
        "seed_generator = keras.random.SeedGenerator(1337)\n",
        "\n",
        "\n",
        "# Sample action from actor\n",
        "@tf.function\n",
        "def sample_action(observation, actor):\n",
        "    logits = actor(observation)\n",
        "    action = keras.ops.squeeze(\n",
        "        keras.random.categorical(logits, 1, seed=seed_generator), axis=1\n",
        "    )\n",
        "    return logits, action\n",
        "\n",
        "\n",
        "# Train the policy by maxizing the PPO-Clip objective\n",
        "@tf.function\n",
        "def train_policy(\n",
        "    observation_buffer, action_buffer, logprobability_buffer, advantage_buffer,\n",
        "    actor, clip_ratio, policy_optimizer, num_actions\n",
        "):\n",
        "    with tf.GradientTape() as tape:  # Record operations for automatic differentiation.\n",
        "        ratio = keras.ops.exp(\n",
        "            logprobabilities(actor(observation_buffer), action_buffer, num_actions)\n",
        "            - logprobability_buffer\n",
        "        )\n",
        "        min_advantage = keras.ops.where(\n",
        "            advantage_buffer > 0,\n",
        "            (1 + clip_ratio) * advantage_buffer,\n",
        "            (1 - clip_ratio) * advantage_buffer,\n",
        "        )\n",
        "\n",
        "        policy_loss = -keras.ops.mean(\n",
        "            keras.ops.minimum(ratio * advantage_buffer, min_advantage)\n",
        "        )\n",
        "    policy_grads = tape.gradient(policy_loss, actor.trainable_variables)\n",
        "    policy_optimizer.apply_gradients(zip(policy_grads, actor.trainable_variables))\n",
        "\n",
        "    kl = keras.ops.mean(\n",
        "        logprobability_buffer\n",
        "        - logprobabilities(actor(observation_buffer), action_buffer, num_actions)\n",
        "    )\n",
        "    kl = keras.ops.sum(kl)\n",
        "    return kl\n",
        "\n",
        "\n",
        "# Train the value function by regression on mean-squared error\n",
        "@tf.function\n",
        "def train_value_function(observation_buffer, return_buffer, critic, value_optimizer):\n",
        "    with tf.GradientTape() as tape:  # Record operations for automatic differentiation.\n",
        "        value_loss = keras.ops.mean((return_buffer - critic(observation_buffer)) ** 2)\n",
        "    value_grads = tape.gradient(value_loss, critic.trainable_variables)\n",
        "    value_optimizer.apply_gradients(zip(value_grads, critic.trainable_variables))"
      ],
      "metadata": {
        "id": "6gH1hCabL7mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameters tuning"
      ],
      "metadata": {
        "id": "NEDZakCZMj3p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # Hyperparameters of the PPO algorithm\n",
        "# steps_per_epoch = 4000\n",
        "# epochs = 5\n",
        "# gamma = 0.99\n",
        "# clip_ratio = 0.2\n",
        "# policy_learning_rate = 3e-4\n",
        "# value_function_learning_rate = 1e-3\n",
        "# train_policy_iterations = 80\n",
        "# train_value_iterations = 80\n",
        "# lam = 0.97\n",
        "# target_kl = 0.01\n",
        "# hidden_sizes = (64, 64)\n",
        "\n",
        "# # True if you want to render the environment\n",
        "# render = False"
      ],
      "metadata": {
        "id": "ClXahAviMRIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization + Training"
      ],
      "metadata": {
        "id": "mhq1lTBZv51-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_experiment(log, title=\"Experiment0\"):\n",
        "    plt.figure(figsize=(8, 5))\n",
        "    plt.plot(log['epoch'], log['mean_return'], label='Mean Return', color='blue')\n",
        "    plt.plot(log['epoch'], log['mean_length'], label='Mean Episode Length', color='red', linestyle='--')\n",
        "    plt.title(f\"{title}\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Value\")\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "ijp61oU6xHls"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def run_experiment(epochs=30, hidden_sizes=(64,64), clip_ratio=0.2, experiment_name=\"exp0\"):\n",
        "\n",
        "  # Hyperparameters of the PPO algorithm\n",
        "  steps_per_epoch = 4000\n",
        "  # epochs = 30\n",
        "  gamma = 0.99\n",
        "  # clip_ratio = 0.2\n",
        "  policy_learning_rate = 3e-4\n",
        "  value_function_learning_rate = 1e-3\n",
        "  train_policy_iterations = 80\n",
        "  train_value_iterations = 80\n",
        "  lam = 0.97\n",
        "  target_kl = 0.01\n",
        "  # hidden_sizes = (64, 64)\n",
        "\n",
        "  # True if you want to render the environment\n",
        "  render = False\n",
        "\n",
        "  # Initialize the environment and get the dimensionality of the\n",
        "  # observation space and the number of possible actions\n",
        "  env = gym.make(\"CartPole-v1\")\n",
        "  observation_dimensions = env.observation_space.shape[0]\n",
        "  num_actions = env.action_space.n\n",
        "\n",
        "  # Initialize the buffer\n",
        "  buffer = Buffer(observation_dimensions, steps_per_epoch)\n",
        "\n",
        "  # Initialize the actor and the critic as keras models\n",
        "  observation_input = keras.Input(shape=(observation_dimensions,), dtype=\"float32\")\n",
        "  logits = mlp(observation_input, list(hidden_sizes) + [num_actions])\n",
        "  actor = keras.Model(inputs=observation_input, outputs=logits)\n",
        "  value = keras.ops.squeeze(mlp(observation_input, list(hidden_sizes) + [1]), axis=1)\n",
        "  critic = keras.Model(inputs=observation_input, outputs=value)\n",
        "\n",
        "  # Initialize the policy and the value function optimizers\n",
        "  policy_optimizer = keras.optimizers.Adam(learning_rate=policy_learning_rate)\n",
        "  value_optimizer = keras.optimizers.Adam(learning_rate=value_function_learning_rate)\n",
        "\n",
        "  # Initialize the observation, episode return and episode length\n",
        "  observation, _ = env.reset()\n",
        "  episode_return, episode_length = 0, 0\n",
        "\n",
        "  log_data = []  # Empty list to store epoch logs\n",
        "\n",
        "  print(f\"Running {experiment_name}\\n\")\n",
        "\n",
        "  # Iterate over the number of epochs\n",
        "  for epoch in range(epochs):\n",
        "      # Initialize the sum of the returns, lengths and number of episodes for each epoch\n",
        "      sum_return = 0\n",
        "      sum_length = 0\n",
        "      num_episodes = 0\n",
        "\n",
        "      # Iterate over the steps of each epoch\n",
        "      for t in range(steps_per_epoch):\n",
        "          if render:\n",
        "              env.render()\n",
        "\n",
        "          # Get the logits, action, and take one step in the environment\n",
        "          observation = observation.reshape(1, -1)\n",
        "          logits, action = sample_action(observation, actor)\n",
        "          observation_new, reward, done, _, _ = env.step(action[0].numpy())\n",
        "          episode_return += reward\n",
        "          episode_length += 1\n",
        "\n",
        "          # Get the value and log-probability of the action\n",
        "          value_t = critic(observation)\n",
        "          logprobability_t = logprobabilities(logits, action, num_actions)\n",
        "\n",
        "          # Store obs, act, rew, v_t, logp_pi_t\n",
        "          buffer.store(observation, action, reward, value_t, logprobability_t)\n",
        "\n",
        "          # Update the observation\n",
        "          observation = observation_new\n",
        "\n",
        "          # Finish trajectory if reached to a terminal state\n",
        "          terminal = done\n",
        "          if terminal or (t == steps_per_epoch - 1):\n",
        "              last_value = 0 if done else critic(observation.reshape(1, -1))\n",
        "              buffer.finish_trajectory(last_value)\n",
        "              sum_return += episode_return\n",
        "              sum_length += episode_length\n",
        "              num_episodes += 1\n",
        "              observation, _ = env.reset()\n",
        "              episode_return, episode_length = 0, 0\n",
        "\n",
        "\n",
        "      # Get values from the buffer\n",
        "      (\n",
        "          observation_buffer,\n",
        "          action_buffer,\n",
        "          advantage_buffer,\n",
        "          return_buffer,\n",
        "          logprobability_buffer,\n",
        "      ) = buffer.get()\n",
        "\n",
        "      # Update the policy and implement early stopping using KL divergence\n",
        "      for _ in range(train_policy_iterations):\n",
        "          kl = train_policy(\n",
        "              observation_buffer, action_buffer, logprobability_buffer, advantage_buffer,\n",
        "              actor, clip_ratio, policy_optimizer, num_actions\n",
        "          )\n",
        "          if kl > 1.5 * target_kl:\n",
        "              # Early Stopping\n",
        "              break\n",
        "\n",
        "      # Update the value function\n",
        "      for _ in range(train_value_iterations):\n",
        "          train_value_function(observation_buffer, return_buffer, critic, value_optimizer)\n",
        "\n",
        "      mean_return = sum_return / num_episodes\n",
        "      mean_length = sum_length / num_episodes\n",
        "\n",
        "      log_data.append({\n",
        "          'epoch': epoch + 1,\n",
        "          'mean_return': mean_return,\n",
        "          'mean_length': mean_length\n",
        "      })\n",
        "\n",
        "\n",
        "      # Print mean return and length for each epoch\n",
        "      print(\n",
        "          f\" Epoch: {epoch + 1}. Mean Return: {sum_return / num_episodes}. Mean Length: {sum_length / num_episodes}\"\n",
        "      )\n",
        "\n",
        "  log_df = pd.DataFrame(log_data)\n",
        "  plot_experiment(log_df, title=experiment_name)\n"
      ],
      "metadata": {
        "id": "WYRcjW-pv46k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 1: Reduce Training Epochs\n",
        "\n",
        "# epochs = 5\n",
        "\n",
        "# Qs: Is the agent improving meaningfully by epoch 5?\n",
        "\n",
        "run_experiment(epochs=5, hidden_sizes=(64,64), clip_ratio=0.2 ,experiment_name=\"Experiment 1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "id": "6EOV2xi2zG1O",
        "outputId": "6a1951cc-18da-49be-d6de-e28a3d59c85f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Experiment 1\n",
            "\n",
            " Epoch: 1. Mean Return: 17.467248908296945. Mean Length: 17.467248908296945\n",
            " Epoch: 2. Mean Return: 21.85792349726776. Mean Length: 21.85792349726776\n",
            " Epoch: 3. Mean Return: 27.397260273972602. Mean Length: 27.397260273972602\n",
            " Epoch: 4. Mean Return: 38.095238095238095. Mean Length: 38.095238095238095\n",
            " Epoch: 5. Mean Return: 62.5. Mean Length: 62.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 2: Increase Hidden Layer Size\n",
        "\n",
        "# hidden_sizes = (128, 128)\n",
        "# epochs = 5\n",
        "\n",
        "# Qs: Any noticeable improvement in convergence speed or return?\n",
        "\n",
        "run_experiment(epochs=5, hidden_sizes=(128, 128), clip_ratio=0.2 ,experiment_name=\"Experiment 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 793
        },
        "id": "6hl1AZLjzGpc",
        "outputId": "0d26b7d0-27af-49e1-98cd-96e5e554d7d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Experiment 2\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"<ipython-input-2-86cb5d89f6c6>\", line 115, in train_policy  *\n        policy_optimizer.apply_gradients(zip(policy_grads, actor.trainable_variables))\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 383, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 422, in apply\n        self.build(trainable_variables)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/adam.py\", line 97, in build\n        self.add_variable_from_reference(\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\", line 35, in add_variable_from_reference\n        return super().add_variable_from_reference(\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 319, in add_variable_from_reference\n        return self.add_variable(\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 274, in add_variable\n        variable = backend.Variable(\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/variables.py\", line 186, in __init__\n        self._initialize_with_initializer(initializer)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/core.py\", line 47, in _initialize_with_initializer\n        self._initialize(lambda: initializer(self._shape, dtype=self._dtype))\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/core.py\", line 38, in _initialize\n        self._value = tf.Variable(\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-e989c3f6660f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Qs: Any noticeable improvement in convergence speed or return?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mrun_experiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_sizes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mexperiment_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Experiment 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-5-2358b7350b45>\u001b[0m in \u001b[0;36mrun_experiment\u001b[0;34m(epochs, hidden_sizes, clip_ratio, experiment_name)\u001b[0m\n\u001b[1;32m     96\u001b[0m       \u001b[0;31m# Update the policy and implement early stopping using KL divergence\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_policy_iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m           kl = train_policy(\n\u001b[0m\u001b[1;32m     99\u001b[0m               \u001b[0mobservation_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogprobability_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madvantage_buffer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m               \u001b[0mactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_ratio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/__autograph_generated_filed32z5h6p.py\u001b[0m in \u001b[0;36mtf__train_policy\u001b[0;34m(observation_buffer, action_buffer, logprobability_buffer, advantage_buffer, actor, clip_ratio, policy_optimizer, num_actions)\u001b[0m\n\u001b[1;32m     13\u001b[0m                     \u001b[0mpolicy_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madvantage_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin_advantage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0mpolicy_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_optimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpolicy_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogprobability_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogprobabilities\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                 \u001b[0mkl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 383\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    420\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables_are_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/adam.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m             self._momentums.append(\n\u001b[0;32m---> 97\u001b[0;31m                 self.add_variable_from_reference(\n\u001b[0m\u001b[1;32m     98\u001b[0m                     \u001b[0mreference_variable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36madd_variable_from_reference\u001b[0;34m(self, reference_variable, name, initializer)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mcolocate_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         ):\n\u001b[0;32m---> 35\u001b[0;31m             return super().add_variable_from_reference(\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mreference_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36madd_variable_from_reference\u001b[0;34m(self, reference_variable, name, initializer)\u001b[0m\n\u001b[1;32m    317\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             )\n\u001b[0;32m--> 319\u001b[0;31m         return self.add_variable(\n\u001b[0m\u001b[1;32m    320\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreference_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36madd_variable\u001b[0;34m(self, shape, initializer, dtype, aggregation, name)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             variable = backend.Variable(\n\u001b[0m\u001b[1;32m    275\u001b[0m                 \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initializer, shape, dtype, trainable, autocast, aggregation, name)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_with_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36m_initialize_with_initializer\u001b[0;34m(self, initializer)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize_with_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_deferred_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         self._value = tf.Variable(\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"<ipython-input-2-86cb5d89f6c6>\", line 115, in train_policy  *\n        policy_optimizer.apply_gradients(zip(policy_grads, actor.trainable_variables))\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 383, in apply_gradients  **\n        self.apply(grads, trainable_variables)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 422, in apply\n        self.build(trainable_variables)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/adam.py\", line 97, in build\n        self.add_variable_from_reference(\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\", line 35, in add_variable_from_reference\n        return super().add_variable_from_reference(\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 319, in add_variable_from_reference\n        return self.add_variable(\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\", line 274, in add_variable\n        variable = backend.Variable(\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/variables.py\", line 186, in __init__\n        self._initialize_with_initializer(initializer)\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/core.py\", line 47, in _initialize_with_initializer\n        self._initialize(lambda: initializer(self._shape, dtype=self._dtype))\n    File \"/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/core.py\", line 38, in _initialize\n        self._value = tf.Variable(\n\n    ValueError: tf.function only supports singleton tf.Variables created on the first call. Make sure the tf.Variable is only created once or created outside tf.function. See https://www.tensorflow.org/guide/function#creating_tfvariables for more information.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment 3: Increase Clip Ratio\n",
        "\n",
        "# clip_ratio = 0.4\n",
        "# hidden_sizes = (64, 64) -- default\n",
        "# epochs = 5\n",
        "\n",
        "# Qs: Is learning faster or more unstable? Any signs of early stopping?\n",
        "\n",
        "run_experiment(epochs=5, hidden_sizes=(64,64), clip_ratio=0.4 ,experiment_name=\"Experiment 3\")"
      ],
      "metadata": {
        "id": "4AVCfCSCyVLH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JdrT8GsrzxPi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}