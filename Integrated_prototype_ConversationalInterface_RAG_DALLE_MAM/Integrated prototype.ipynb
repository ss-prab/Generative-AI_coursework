{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "L4",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Candidate name:** Sneha Santha Prabakar\n",
        "\n",
        "**Capstone Project**"
      ],
      "metadata": {
        "id": "lhiLrqlFl63B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook includes:\n",
        "- Conversational memory chat\n",
        "- PDF-based document QA using RAG\n",
        "- Prompt-based image generation\n",
        "- SQL query assistant\n",
        "- Book recommendation agent\n",
        "- Weather response agent\n",
        "- Smart controller routing based on user input\n",
        "\n",
        "It is **self-contained**, Colab-compatible, and meant to simulate a mini AI assistant."
      ],
      "metadata": {
        "id": "wxbJYiJOmh2X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Executive Summary**\n",
        "\n",
        "This project implements a multi-agent AI assistant system that demonstrates the integration of seven different AI capabilities through a unified controller. The system includes conversational memory, document querying with RAG, image generation, weather services, recommendation engines, and intelligent routing. Each component operates independently while being coordinated through a smart controller that analyzes user intent and routes requests to the appropriate agent, at the end.\n",
        "\n",
        "The implementation showcases practical applications of current AI technologies including OpenAI‚Äôs GPT-4o, DALL-E 3, vector databases, and external API integrations, all working together to create a comprehensive AI assistant."
      ],
      "metadata": {
        "id": "sHKCLpTByXWT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 1: Environment Set-up"
      ],
      "metadata": {
        "id": "QKHM41zt0fkB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2KDobHala1k",
        "outputId": "149ba548-dca7-4954-f491-682fd7aa4912"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.26)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.96.1)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.11.0.post1)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (5.0.0)\n",
            "Requirement already satisfied: pypdf in /usr/local/lib/python3.11/dist-packages (5.8.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.68)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.53.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.15.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.33.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.2.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.7.9)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.5)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain) (1.33)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain) (3.0.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# üì¶ Install all required packages\n",
        "!pip install -U langchain langchain-community openai faiss-cpu sentence-transformers pypdf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "\n",
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "# Memory Chat\n",
        "from langchain.chains import ConversationChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "# from langchain.llms import OpenAI\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Document-querying and RAG Chat\n",
        "from google.colab import files\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Weather agent + SQL db + activities recommendation system\n",
        "import requests\n",
        "import openai\n",
        "from datetime import datetime\n",
        "import json\n",
        "import sqlite3\n",
        "import re\n"
      ],
      "metadata": {
        "id": "FFGhYZWbI0FM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# üîê Secure API Key Handling\n",
        "# We use `getpass()` so your OpenAI API key is never printed or stored in plaintext.\n",
        "\n",
        "OPENAI_API_KEY = getpass(\"Enter your OpenAI API key: \")\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
        "\n",
        "WEATHER_API_KEY = getpass(\"Enter your Weather API key: \")\n",
        "os.environ[\"WEATHER_API_KEY\"] = WEATHER_API_KEY\n",
        "\n",
        "TMDB_API_KEY = getpass(\"Enter your TMDB API key: \")\n",
        "os.environ[\"TMDB_API_KEY\"] = TMDB_API_KEY\n",
        "\n",
        "GOOGLE_BOOKS_API_KEY = getpass(\"Enter your Google Books API key: \")\n",
        "os.environ[\"GOOGLE_BOOKS_API_KEY\"] = GOOGLE_BOOKS_API_KEY\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y6YM2Ds7mlCy",
        "outputId": "098a9685-4422-4a42-9ef5-26697c09aa0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter your OpenAI API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Enter your Weather API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Enter your TMDB API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Enter your Google Books API key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 2: Conversational Interface"
      ],
      "metadata": {
        "id": "d_AnurLQ0nR_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal:**\n",
        "\n",
        "The goal of this section is to build a simple yet effective conversational AI assistant that can handle a natural, multi-turn dialogue with the user. It uses OpenAI‚Äôs GPT-4o, the most up-to-date large language model I have access to, to generate relevant and coherent responses.\n",
        "\n",
        "\n",
        "**How it works:**\n",
        "\n",
        "This setup uses LangChain‚Äôs `ConversationChain` combined with `ConversationBufferMemory`.\n",
        "\n",
        "The `ConversationBufferMemory` keeps track of what the user says in each turn so that the assistant can remember the flow of the conversation.\n",
        "\n",
        "The `ConversationChain` passes each user query, along with the stored memory, to the LLM - so follow-up questions can build on previous answers.\n",
        "\n",
        "I specifically chose GPT-4o because it is the latest version with a more recent knowledge cutoff (2023) than older GPT-3.5 or GPT-4 models, which means it can provide more relevant, up-to-date general context when talking about broad topics like global AI governance.\n",
        "\n",
        "**Result:**\n",
        "\n",
        "The result is an interactive AI assistant bot that you can chat with by typing your questions. It can handle coherent turns and the conversation runs until you type exit to end it.\n",
        "\n",
        "The `üë§ User` shows the user input.\n",
        "\n",
        "And the `ü§ñ Assistant` shows the bot's response.\n",
        "\n",
        "**Application:**\n",
        "\n",
        "In the context of AI policy and governance, this kind of conversational interface can help:\n",
        "\n",
        "Students, researchers, or policymakers explore broad concepts around AI governance and global strategies in a conversational way.\n",
        "\n",
        "Test ideas and follow-up questions without needing to search multiple sources manually.\n",
        "\n",
        "Serve as a prototype for how a real policy chatbot could assist with simple clarifications, explanations, or brainstorming sessions.\n",
        "\n",
        "While this version only uses the general LLM, the same conversational memory approach can later be combined with document retrieval (RAG) or live tools to make the assistant more factual and context-specific. We will explore this in the next section of this notebook."
      ],
      "metadata": {
        "id": "0OQbgsYrJPbk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the conversation memory\n",
        "simple_memory = ConversationBufferMemory()\n",
        "\n",
        "# Use the plain OpenAI LLM\n",
        "# llm_simple = OpenAI(temperature=0.5)\n",
        "\n",
        "llm = ChatOpenAI(\n",
        "    model_name=\"gpt-4o\", # more up-to-date than a simple LLM model\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "# Build the basic conversation chain\n",
        "conversation = ConversationChain(\n",
        "    llm=llm,\n",
        "    memory=simple_memory\n",
        ")\n",
        "\n",
        "\n",
        "def memory_chat(user_prompt=\"\"):\n",
        "    if len(user_prompt):\n",
        "        response = conversation.run(user_prompt)\n",
        "        return f\"ü§ñ Assistant: {response}\\n\"\n",
        "    else:\n",
        "        print(\"üí¨ AI Assistant - Ask Anything!\")\n",
        "        print(\"Type 'exit' to end the conversation.\\n\")\n",
        "        while True:\n",
        "            user_input = input(\"üë§ User: \")\n",
        "            if user_input.lower() in [\"exit\", \"quit\"]:\n",
        "                print(\"\\n‚úÖ Conversation ended.\")\n",
        "                break\n",
        "            response = conversation.run(user_input)\n",
        "            print(f\"ü§ñ Assistant: {response}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4i6Gtj9BJdAx",
        "outputId": "8c430ae9-d9af-4471-b9d1-7b905058a42d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4-771616342.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  simple_memory = ConversationBufferMemory()\n",
            "/tmp/ipython-input-4-771616342.py:7: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI(\n",
            "/tmp/ipython-input-4-771616342.py:13: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
            "  conversation = ConversationChain(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory_chat(\"What is Antartica?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "iB-fMDCsIrq8",
        "outputId": "52238649-c25e-4cc4-d7a6-b93c41655394"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-4-771616342.py:21: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = conversation.run(user_prompt)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"ü§ñ Assistant: Antarctica is the southernmost continent on Earth, containing the geographic South Pole. It is the fifth-largest continent, covering about 14 million square kilometers (5.4 million square miles), which is roughly 1.3 times the size of Europe. Despite its size, it is the least populated continent, with no permanent residents. The population varies from about 1,000 in winter to around 5,000 in summer, consisting mainly of researchers and scientists from various countries who live in research stations scattered across the continent.\\n\\nAntarctica is known for its extreme cold, with temperatures that can drop below -80 degrees Celsius (-112 degrees Fahrenheit) in the interior. The continent is covered by an ice sheet that contains about 60% of the world's fresh water. This ice sheet is, on average, about 1.9 kilometers (1.2 miles) thick, and in some places, it can be over 4.8 kilometers (3 miles) thick.\\n\\nThe Antarctic Treaty, signed in 1959 by 12 countries and now having over 50 signatories, sets aside Antarctica as a scientific preserve, establishes freedom of scientific investigation, and bans military activity on the continent. The unique ecosystem of Antarctica includes species such as penguins, seals, and various types of seabirds, all adapted to the harsh conditions. The surrounding Southern Ocean is rich in marine life, including krill, which is a crucial part of the food web.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory_chat(\"Where is it?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "Q9V9JBA_LZxo",
        "outputId": "bfa6cfb9-2d28-45f5-a32d-627603145f11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ü§ñ Assistant: Antarctica is located at the southernmost part of the Earth, surrounding the South Pole. It is situated almost entirely south of the Antarctic Circle, which is an imaginary line of latitude at approximately 66.5 degrees south of the Equator. The continent is bordered by the Southern Ocean, which encircles it and separates it from the other continents. Due to its remote location, Antarctica is quite isolated, with the closest landmasses being the southern tips of South America, Africa, and Australia.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory_chat(\"What is it's population size?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "5Uii7IA0Lq-X",
        "outputId": "480b56cd-ab77-4356-9a6a-6c2ab80121fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"ü§ñ Assistant: Antarctica does not have a permanent population. Instead, it hosts a transient population of researchers and scientists who live in research stations across the continent. The population size varies depending on the season. During the winter months, the population is around 1,000 people, while in the summer, it increases to approximately 5,000. These individuals come from various countries and are primarily involved in scientific research and exploration. The temporary nature of the population is due to the extreme environmental conditions and the continent's designation as a scientific preserve under the Antarctic Treaty.\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory_chat(\"Hi again, what did I ask earlier?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "2q-OUNall3lk",
        "outputId": "5162c54d-5d5f-41fb-b91c-67cc545e2f17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ü§ñ Assistant: Earlier, you asked about Antarctica, including what it is, where it is located, and its population size. We discussed its status as the southernmost continent, its extreme climate, the presence of research stations, and the seasonal variation in its population. If you have more questions or need further details, feel free to ask!\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "memory_chat()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAOrwtI4qifV",
        "outputId": "10e6c4dd-253b-4b0c-f4f1-b82d63ed5c4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üí¨ AI Assistant - Ask Anything!\n",
            "Type 'exit' to end the conversation.\n",
            "\n",
            "üë§ User: Tell me about the AI Action Plan and the important factors in it.\n",
            "ü§ñ Assistant: The AI Action Plan is a strategic framework that various governments and organizations have developed to guide the development, deployment, and regulation of artificial intelligence technologies. While specific details can vary depending on the entity creating the plan, there are several common important factors typically included:\n",
            "\n",
            "1. **Ethical Guidelines**: Ensuring that AI systems are developed and used in ways that are ethical and respect human rights. This includes considerations around privacy, fairness, transparency, and accountability.\n",
            "\n",
            "2. **Research and Development**: Promoting innovation in AI through funding and support for research initiatives. This often involves collaboration between government, academia, and industry to advance AI technologies.\n",
            "\n",
            "3. **Education and Workforce Development**: Preparing the workforce for the changes brought about by AI through education and training programs. This includes upskilling current workers and integrating AI-related topics into educational curricula.\n",
            "\n",
            "4. **Regulation and Governance**: Establishing regulatory frameworks to ensure the safe and responsible use of AI. This can involve creating standards for AI systems, addressing issues like data protection, and setting up oversight bodies.\n",
            "\n",
            "5. **Public and Private Sector Collaboration**: Encouraging partnerships between the public and private sectors to leverage AI for economic growth and societal benefit. This includes sharing best practices and resources.\n",
            "\n",
            "6. **International Cooperation**: Engaging in international dialogue and cooperation to address global challenges related to AI, such as cross-border data flows and the development of international standards.\n",
            "\n",
            "7. **Addressing Societal Impact**: Considering the broader societal implications of AI, such as its impact on employment, inequality, and social well-being, and developing strategies to mitigate negative effects.\n",
            "\n",
            "These factors aim to ensure that AI technologies are developed in a way that maximizes benefits while minimizing risks, fostering an environment where AI can contribute positively to society.\n",
            "\n",
            "üë§ User: Tell me more about individual countries - US, EU, China, Japan and India\n",
            "ü§ñ Assistant: Certainly! Each of these regions and countries has its own approach to AI development and regulation, reflecting their unique priorities and challenges. Here's a brief overview of their AI strategies:\n",
            "\n",
            "1. **United States**:\n",
            "   - The U.S. has been a leader in AI research and development, with significant contributions from both the private sector and academia.\n",
            "   - The National AI Initiative Act of 2020 aims to ensure continued U.S. leadership in AI by promoting research, development, and education.\n",
            "   - The U.S. focuses on fostering innovation, ensuring national security, and addressing ethical considerations in AI deployment.\n",
            "   - Agencies like the National Institute of Standards and Technology (NIST) are involved in developing AI standards and guidelines.\n",
            "\n",
            "2. **European Union**:\n",
            "   - The EU emphasizes ethical AI, with a strong focus on privacy, data protection, and human rights.\n",
            "   - The European Commission has proposed regulations like the AI Act, which categorizes AI applications by risk and sets requirements accordingly.\n",
            "   - The EU aims to create a single market for AI, promoting innovation while ensuring safety and trust.\n",
            "   - Initiatives like the Horizon Europe program fund AI research and innovation across member states.\n",
            "\n",
            "3. **China**:\n",
            "   - China has a national strategy to become a global leader in AI by 2030, with significant government investment in AI research and development.\n",
            "   - The country focuses on integrating AI into various sectors, including manufacturing, healthcare, and urban planning.\n",
            "   - China emphasizes the use of AI for economic growth and societal development, with a strong focus on data-driven AI applications.\n",
            "   - The government is also working on developing ethical guidelines and standards for AI.\n",
            "\n",
            "4. **Japan**:\n",
            "   - Japan's AI strategy is part of its broader Society 5.0 initiative, which aims to create a super-smart society by integrating AI and other technologies.\n",
            "   - The country focuses on using AI to address societal challenges, such as an aging population and labor shortages.\n",
            "   - Japan emphasizes collaboration between industry, academia, and government to advance AI research and applications.\n",
            "   - Ethical considerations and human-centric AI are important aspects of Japan's approach.\n",
            "\n",
            "5. **India**:\n",
            "   - India aims to leverage AI for inclusive growth and development, focusing on sectors like agriculture, healthcare, and education.\n",
            "   - The National Strategy for AI, developed by NITI Aayog, outlines India's vision to become a leader in AI by promoting research, innovation, and skill development.\n",
            "   - India emphasizes the use of AI for social empowerment and addressing challenges unique to the country, such as rural development.\n",
            "   - The government is working on creating a regulatory framework to ensure the ethical and responsible use of AI.\n",
            "\n",
            "Each of these regions and countries is navigating the opportunities and challenges of AI in ways that align with their strategic goals and societal needs.\n",
            "\n",
            "üë§ User: How does their policies affect Singapore?\n",
            "ü§ñ Assistant: Singapore, as a global hub for technology and innovation, closely monitors and often aligns its policies with international trends in AI development and regulation. The AI strategies of major players like the US, EU, China, Japan, and India can influence Singapore in several ways:\n",
            "\n",
            "1. **Innovation and Collaboration**: Singapore actively seeks to collaborate with leading AI nations to foster innovation. The policies and advancements in AI from these countries can provide opportunities for partnerships in research and development, allowing Singapore to leverage global expertise and technology.\n",
            "\n",
            "2. **Regulatory Frameworks**: As countries like the EU develop comprehensive AI regulations, Singapore may look to these frameworks as benchmarks or inspiration for its own regulatory approaches. This can help ensure that Singapore's AI policies are aligned with international standards, facilitating cross-border cooperation and trade.\n",
            "\n",
            "3. **Ethical and Responsible AI**: With a strong emphasis on ethical AI, Singapore can draw insights from the ethical guidelines and standards being developed in regions like the EU and Japan. This can help Singapore refine its own ethical frameworks to ensure AI technologies are used responsibly and transparently.\n",
            "\n",
            "4. **Economic Competitiveness**: The AI strategies of major economies can impact global market dynamics. Singapore, with its open economy, needs to stay competitive by adopting best practices and innovations from these countries. This includes investing in AI research, talent development, and infrastructure to maintain its position as a leading tech hub.\n",
            "\n",
            "5. **Talent Development**: As countries invest in AI education and workforce development, Singapore can benefit by attracting skilled professionals and researchers. Additionally, Singapore can enhance its own educational programs by incorporating successful elements from other countries' AI education strategies.\n",
            "\n",
            "6. **Sectoral Impact**: The focus areas of AI application in countries like India (agriculture, healthcare) and Japan (addressing societal challenges) can provide Singapore with insights into potential sectors for AI deployment. This can guide Singapore in identifying and prioritizing sectors where AI can have the most significant impact.\n",
            "\n",
            "Overall, while Singapore develops its own AI strategies tailored to its unique context, it remains influenced by the policies and advancements of major AI players, ensuring it remains at the forefront of AI innovation and governance.\n",
            "\n",
            "üë§ User: Can you summarise the main factors of AI Action Plan you mentioned before?\n",
            "ü§ñ Assistant: Certainly! Here's a summary of the main factors typically included in an AI Action Plan:\n",
            "\n",
            "1. **Ethical Guidelines**: Ensuring AI systems are developed and used ethically, respecting human rights, privacy, fairness, transparency, and accountability.\n",
            "\n",
            "2. **Research and Development**: Promoting AI innovation through funding and support for research, often involving collaboration between government, academia, and industry.\n",
            "\n",
            "3. **Education and Workforce Development**: Preparing the workforce for AI-driven changes through education and training, including upskilling and integrating AI into curricula.\n",
            "\n",
            "4. **Regulation and Governance**: Establishing frameworks to ensure safe and responsible AI use, including standards, data protection, and oversight bodies.\n",
            "\n",
            "5. **Public and Private Sector Collaboration**: Encouraging partnerships to leverage AI for economic growth and societal benefit, sharing best practices and resources.\n",
            "\n",
            "6. **International Cooperation**: Engaging in global dialogue to address AI-related challenges, such as cross-border data flows and international standards.\n",
            "\n",
            "7. **Addressing Societal Impact**: Considering AI's broader societal implications, like employment and inequality, and developing strategies to mitigate negative effects.\n",
            "\n",
            "These factors aim to maximize AI's benefits while minimizing risks, fostering an environment where AI can positively contribute to society.\n",
            "\n",
            "üë§ User: exit\n",
            "\n",
            "‚úÖ Conversation ended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 3: Document-querying"
      ],
      "metadata": {
        "id": "wvdnfIS0JZMH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal:**\n",
        "\n",
        "The goal of this section is to demonstrate how combining Retrieval-Augmented Generation (RAG) with conversational memory can make a language model more reliable when answering questions that require accurate, domain-specific information ‚Äî in this case, AI governance.\n",
        "\n",
        "Instead of relying solely on what the model ‚Äúknows‚Äù from training, this approach ensures that answers are directly supported by a relevant policy document.\n",
        "\n",
        "**Chosen Document: Singapore‚Äôs National AI Strategy 2.0**\n",
        "\n",
        "https://file.go.gov.sg/nais2023.pdf\n",
        "\n",
        "With Generative AI advancing so quickly, strong governance frameworks are more important than ever to manage risks like ethics, privacy, fairness, and accountability. Singapore‚Äôs National AI Strategy 2.0 (AI for Public Good) is a practical example of how a country is putting clear principles and safeguards in place to make sure AI benefits everyone while minimising potential harm. That makes it a meaningful document to test how an AI assistant can help people navigate complex policy information.\n",
        "\n",
        "I chose this document because it ties directly to my research on Generative AI risk assessment, supply chain dynamics, and regulatory compliance. I focused on the introduction, the strategic pillars of the strategy, and especially System 3: Infrastructure & Environment, which sets out how Singapore is building the trusted environment and infrastructure needed for safe, responsible AI development and use.\n",
        "\n",
        "By focusing on these sections, I can make sure the assistant retrieves meaningful, policy-relevant information ‚Äî not just generic or unrelated text.\n",
        "\n",
        "**How it works:**\n",
        "\n",
        "- The selected pages are loaded and divided into smaller, meaningful text chunks.\n",
        "\n",
        "- Each chunk is embedded and stored in a vector database, enabling semantic search.\n",
        "\n",
        "- For each user question, the system searches for the most relevant chunks.\n",
        "\n",
        "- A Conversational Retrieval Chain combines these retrieved sections with the conversation history, allowing the assistant to keep track of previous questions and provide consistent answers.\n",
        "\n",
        "- The language model then generates a final response that uses the retrieved content and the chat history to generate clear, factual answers.\n",
        "\n",
        "**Result:**\n",
        "\n",
        "There are two types of outcomes:\n",
        "\n",
        "1. The assistant can handle direct, single-turn semantic queries, providing clear, factual answers based on the policy document. For example, I tested questions such as:\n",
        "\n",
        "  - ‚ÄúWhat shifts is Singapore making from its first AI strategy to NAIS 2.0?‚Äù\n",
        "\n",
        "  - ‚ÄúWhat is AI Verify and how does it support AI governance?‚Äù\n",
        "\n",
        "  - ‚ÄúWhat is Singapore‚Äôs role in international AI governance efforts?‚Äù\n",
        "\n",
        "These in-line queries show how the system retrieves the most relevant sections of the document and generates precise, contextual responses.\n",
        "\n",
        "2. It also works as an interactive conversational assistant, where users can input follow-up questions in a multi-turn dialogue. The conversational memory ensures that the assistant keeps track of what has already been discussed, providing continuity and context across multiple queries - similar to how a real policy advisor might respond.\n",
        "\n",
        "Together, these capabilities demonstrate how retrieval and memory can work hand in hand to make an AI assistant more accurate, context-aware, and useful for engaging with detailed governance frameworks.\n",
        "\n",
        "**Application:**\n",
        "\n",
        "This approach directly supports the Trusted Environment pillar of Singapore‚Äôs AI strategy by showing how complex policy information can be made more accessible and useful to the people who need it.\n",
        "\n",
        "In practice, a tool like this could be used by:\n",
        "\n",
        "- Policy teams and civil servants, who may need quick answers to detailed questions about AI risk levels, governance frameworks, or compliance measures.\n",
        "\n",
        "Businesses and citizens, who want to better understand how national AI policies affect their work or daily lives.\n",
        "\n",
        "Companies developing AI systems, who can use it to check that their solutions align with national guidelines on privacy, fairness, and accountability.\n",
        "\n",
        "By combining retrieval with conversational memory, this assistant helps translate policy documents into practical, understandable information ‚Äî supporting Singapore‚Äôs goal of promoting AI for the public good."
      ],
      "metadata": {
        "id": "Kc3iezLLF7Fy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. User Upload - Policy Document"
      ],
      "metadata": {
        "id": "OABf_9wzE2mo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Source document: https://file.go.gov.sg/nais2023.pdf"
      ],
      "metadata": {
        "id": "lTgoNHl2E8PE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "YFt0dGTyqBep",
        "outputId": "13cb9afe-f6d7-4c23-a13d-9220929847fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bed62fa8-ef36-421c-85a0-f112a70e0444\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bed62fa8-ef36-421c-85a0-f112a70e0444\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving SG AI for public good.pdf to SG AI for public good (2).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2. Load the PDF, Filter Key Pages, and Chunk for Embeddings"
      ],
      "metadata": {
        "id": "BCzY2iYUJeDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Load the entire PDF\n",
        "loader = PyPDFLoader(\"/content/SG AI for public good.pdf\")\n",
        "all_pages = loader.load()\n",
        "\n",
        "print(f\"Total pages in PDF: {len(all_pages)}\")\n",
        "\n",
        "# 2. Select only the key pages you want\n",
        "# Note: PDF page 7 = index 6 (as Python is 0-indexed)\n",
        "selected_pages = [\n",
        "    all_pages[i] for i in list(range(6, 12))  # pages 7‚Äì12\n",
        "    + list(range(14, 16))                     # pages 15‚Äì16\n",
        "    + list(range(57, 64))                     # pages 58‚Äì64\n",
        "]\n",
        "\n",
        "print(f\"Selected pages: {len(selected_pages)}\")\n",
        "\n",
        "# 3. Chunk the selected pages\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=800, chunk_overlap=100)\n",
        "\n",
        "chunks = splitter.split_documents(selected_pages)\n",
        "\n",
        "print(f\"Created {len(chunks)} chunks\")\n",
        "\n",
        "# 4. Display 3 sample chunks\n",
        "for i, chunk in enumerate(chunks[:3]):\n",
        "    print(f\"\\n--- Chunk {i+1} ---\\n{chunk.page_content}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtmAWWI9BhZO",
        "outputId": "3743a34f-b341-48c9-b394-746a567616c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total pages in PDF: 68\n",
            "Selected pages: 15\n",
            "Created 34 chunks\n",
            "\n",
            "--- Chunk 1 ---\n",
            "INTRODUCTION | 5\n",
            "Since the release of ChatGPT by OpenAI on 30 November 2022, Artificial Intelligence \n",
            "(AI)1 has gone mainstream. Recent breakthroughs, particularly those in the realm \n",
            "of Generative AI, have resulted in AI proliferating quickly. AI is moving beyond \n",
            "its traditional, narrow approaches, towards more general, almost human-like \n",
            "characteristics. The ability of ChatGPT to draft, depict, translate, understand \n",
            "context, and provide seemingly meaningful responses to our questions, has \n",
            "captured the imagination of not just scientists and experts, but all of us. For \n",
            "governments, these developments have raised new and critical questions around \n",
            "the risks and responsibilities associated with the development and use of such a\n",
            "\n",
            "\n",
            "--- Chunk 2 ---\n",
            "the risks and responsibilities associated with the development and use of such a \n",
            "powerful technology, even as AI continues to reinforce and remind us of what it \n",
            "means to be human.\n",
            "In Singapore, where the vast majority of our people already frequently interact \n",
            "with digital technologies to transact with the Government and businesses, and are \n",
            "also digitally engaged at work, AI has been both commonplace and an uncommon \n",
            "force. \n",
            "Introduction\n",
            "1 AI refers to a set of capabilities through which computer systems can demonstrate human-\n",
            "like behaviour and complete tasks which typically require human intelligence. It is considered a \n",
            "general-purpose technology which can be applied across a wide range of sectors. Some of its varied\n",
            "\n",
            "\n",
            "--- Chunk 3 ---\n",
            "general-purpose technology which can be applied across a wide range of sectors. Some of its varied \n",
            "applications include advanced web search, recommendation and decision systems, advanced \n",
            "problem-solving, understanding speech and natural language, perception (for applications like \n",
            "facial recognition, image labelling, or autonomous vehicles ), and Generative AI tools (including \n",
            "Large Language Models ) that can produce various types of content, including text, images, audio, \n",
            "and synthetic data.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This setup combines semantic retrieval with a LLM to build a practical Retrieval-Augmented Generation (RAG) system with conversational memory.\n",
        "\n",
        "For every user query:\n",
        "1. The retriever searches the vector store (FAISS) for the most relevant chunks from the embedded PDF.\n",
        "2. It feeds these chunks, along with the user‚Äôs current question and the entire chat history, into the LLM‚Äôs prompt.\n",
        "3. The LLM then generates a final answer that stays factual and context-aware, grounding its response in the retrieved policy content instead of relying only on its pre-trained knowledge.\n",
        "\n",
        "This approach ensures the chatbot can handle multi-turn conversations while providing accurate, document-based answers. It‚Äôs especially useful when we want our assistant to stay aligned with a specific source ‚Äî for example, this Singapore National AI Strategy PDF ‚Äî rather than drifting off-topic."
      ],
      "metadata": {
        "id": "GeAA77ohD-ah"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3. Integrate Embeddings, Vector Store, and LLM for RAG Chat"
      ],
      "metadata": {
        "id": "e-e9LEJIe6HN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create embeddings and build the vector store:\n",
        "embeddings = OpenAIEmbeddings()\n",
        "vectorstore = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "# Initialize the LLM (using OpenAI Chat model) with zero temperature for factual answers\n",
        "llm_context = ChatOpenAI(temperature=0)\n",
        "\n",
        "# Create conversational memory to track chat history across turns\n",
        "memory_context = ConversationBufferMemory(\n",
        "    memory_key=\"chat_history\", # Key used by LangChain to store conversation context\n",
        "    return_messages=True) # Return previous messages for continuity\n",
        "\n",
        "# Build the Conversational Retrieval Chain\n",
        "# This combines the LLM, retriever (vector store), and memory into one chain\n",
        "qa_chain = ConversationalRetrievalChain.from_llm(\n",
        "    llm=llm_context,\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    memory=memory_context\n",
        ")\n",
        "\n",
        "def document_q_n_a(question):\n",
        "  return qa_chain.run(question)\n",
        "\n",
        "# Test the chain with an example semantic query\n",
        "question = \"What are the three systems of Singapore's National AI Strategy 2.0?\"\n",
        "# answer = qa_chain.run(question)\n",
        "answer = document_q_n_a(question)\n",
        "\n",
        "# Display the user query and the assistant's generated answer\n",
        "print(f\"\\nUser: {question}\\nAssistant: {answer}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HlnpgaKm7u64",
        "outputId": "b2e133f8-602b-431e-8fd3-6988d073989b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-12-90016934.py:2: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
            "  embeddings = OpenAIEmbeddings()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User: What are the three systems of Singapore's National AI Strategy 2.0?\n",
            "Assistant: The three systems of Singapore's National AI Strategy 2.0 are:\n",
            "\n",
            "1. System 1: Industry (Enablers: Talent, Data, Funding, Demand)\n",
            "2. System 2: Research (Enablers: Talent, Data, Funding, Demand)\n",
            "3. System 3: Infrastructure & Environment (Enablers: Compute, Data, Trusted Environment, Leader in Thought and Action)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4. Direct, single-turn semantic queries based on the document"
      ],
      "metadata": {
        "id": "s5BaltU4e-6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    \"What shifts is Singapore making from its first AI strategy to NAIS 2.0\",\n",
        "    \"What is AI Verify and how does it support AI governance?\",\n",
        "    \"What is Singapore‚Äôs role in international AI governance efforts?\"\n",
        "]\n",
        "\n",
        "for curr_q in questions:\n",
        "    answer = document_q_n_a(curr_q)\n",
        "    print(f\"\\nUser: {curr_q}\\nAssistant: {answer}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "STUKz3ul-pft",
        "outputId": "396addeb-0751-422a-b6c4-119f5a0db865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User: What shifts is Singapore making from its first AI strategy to NAIS 2.0\n",
            "Assistant: Singapore is making three key shifts from its first National AI Strategy to NAIS 2.0:\n",
            "\n",
            "1. From Opportunity to Necessity: Shifting the perspective of AI from being seen as an opportunity to a necessity. It is essential for people to have knowledge about AI, not just consider it as a \"good to have.\" This shift aims to maximize AI's potential for Singapore by having both technical experts and savvy users.\n",
            "\n",
            "2. From Local to Global: Transitioning from a local focus to a global ambition in AI. Singapore aims to be world-leading in AI and well-connected to global innovation networks. The goal is to work with the best globally to address complex challenges related to AI, such as energy, data, and ethics, and contribute to valuable AI breakthroughs and products worldwide.\n",
            "\n",
            "3. From Projects to Systems: Moving from individual flagship National AI Projects to a systems approach. This shift involves bringing together stakeholders within and outside Singapore to enhance resources, capabilities, infrastructure, and accelerate the exchange of ideas. The aim is to administer AI-enabled solutions at scale for a widespread positive impact on the economy and society.\n",
            "\n",
            "\n",
            "User: What is AI Verify and how does it support AI governance?\n",
            "Assistant: AI Verify is an AI governance testing framework and software toolkit developed by IMDA. It consists of 11 AI ethics principles that are in line with internationally recognized frameworks. AI Verify helps organizations validate the performance of their AI systems against these principles through standardized tests. The AI Verify Foundation was also established to enhance AI testing capabilities globally. It aims to ensure that companies and regulators can meet the needs of responsible AI development and deployment.\n",
            "\n",
            "\n",
            "User: What is Singapore‚Äôs role in international AI governance efforts?\n",
            "Assistant: Singapore plays a significant role in international AI governance efforts by actively participating in multi-stakeholder platforms such as the Global Partnership on AI (GPAI), the World Economic Forum (WEF) AI Governance Alliance, and the United Nations (UN) High-Level Advisory Body on AI. Singapore is committed to being a serious and reliable international partner on AI innovation and governance. They have developed governance frameworks and tools like AI Verify, demonstrating their commitment to responsible and ethical AI use. Singapore's initiatives have been recognized globally, and they aim to continue growing their international networks with key partner countries and leading AI companies to promote practical and risk-based approaches to AI.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.5. Context-Aware Interactive conversational assistant"
      ],
      "metadata": {
        "id": "sCULopOffIQc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample questions used to interact with the AI assistant bot:\n",
        "\n",
        "What is AI?\n",
        "\n",
        "What does the document say about this?\n",
        "\n",
        "Can you summarise the actions?\n",
        "\n",
        "How does this connect to privacy?"
      ],
      "metadata": {
        "id": "cCao3nm59Vim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"üí¨ Start chatting with the AI assistant! (Type 'exit' to stop)\\n\")\n",
        "\n",
        "while True:\n",
        "    # Take user input each time\n",
        "    user_question = input(\"üë§ User: \")\n",
        "\n",
        "    # Check if the user wants to stop\n",
        "    if user_question.lower() in [\"exit\", \"quit\"]:\n",
        "        print(\"\\n‚úÖ Chat ended.\")\n",
        "        break\n",
        "\n",
        "    # Run the question through your Conversational Retrieval Chain\n",
        "    answer = qa_chain.run(user_question)\n",
        "\n",
        "    # Show the assistant's response\n",
        "    print(f\"ü§ñ Assistant: {answer}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQkaphTDLXss",
        "outputId": "fb8eac75-efb3-497e-bc00-4e43f51146ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üí¨ Start chatting with the AI assistant! (Type 'exit' to stop)\n",
            "\n",
            "üë§ User: What is AI?\n",
            "ü§ñ Assistant: AI refers to a set of capabilities through which computer systems can demonstrate human-like behavior and complete tasks that typically require human intelligence. It is considered a general-purpose technology that can be applied across a wide range of sectors. AI has the ability to learn, reason, and solve problems in ways that mimic human cognitive functions.\n",
            "\n",
            "üë§ User: What does the document say about this?\n",
            "ü§ñ Assistant: The document highlights that AI can be a potent force for good, uplifting human potential by transforming cognitive and physical tasks. It emphasizes steering AI for the public good to create positive impacts, new opportunities, better jobs, and meaningful connections. Additionally, it stresses the strategic importance of investing in AI to unlock economic growth and overcome labor and productivity challenges. The document also mentions the need for a regulatory environment that is pro-innovation while ensuring appropriate guardrails, including updating governance frameworks to address novel risks like Generative AI.\n",
            "\n",
            "üë§ User: Can you summarise the actions?\n",
            "ü§ñ Assistant: Some actions that can be summarized from the document include:\n",
            "\n",
            "1. Continuing to work with partners on R&D, particularly around alignment and evaluations.\n",
            "2. Translating guidelines into appropriate technical standards, tools, and services that can be practically applied.\n",
            "3. Implementing policy measures such as regulatory sandboxes and pilots for solutions like watermarking and model cards.\n",
            "4. Developing capabilities to nurture a domestic Testing, Inspection, and Certification (TIC) sector.\n",
            "5. Designing interventions that are risk-based, tiered, and adapted for specific vertical sectors and horizontal applications to address different considerations and risks in AI use cases.\n",
            "\n",
            "üë§ User: How does this connect to privacy?\n",
            "ü§ñ Assistant: The document connects AI actions to privacy considerations by highlighting the importance of addressing risks and responsibilities associated with the development and use of AI, especially in the context of privacy and security. It mentions concerns over safety and security risks of AI, particularly in relation to Generative AI models. The document emphasizes the need for clear responsibilities for actors across the AI supply chain and the importance of establishing baseline guidance to ensure responsible design and use of AI. Additionally, it mentions the inscrutability of large language models (LLMs) and the concerns it raises about the validity, credibility, and legality of their output, which are all connected to privacy considerations.\n",
            "\n",
            "üë§ User: exit\n",
            "\n",
            "‚úÖ Chat ended.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 4: Image Generation with Prompt Engineering"
      ],
      "metadata": {
        "id": "PZLz_-8JhoO2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Goal:** Handle diverse prompts and conduct structured prompt experimentation when generating images with DALL¬∑E API\n",
        "\n",
        "**How it works:** I have run a sequence of prompts that gradually adds scene complexity, technical specifications, and style changes ‚Äî so I could observe exactly how different wording and details affect the final result.\n",
        "\n",
        "**Prompts used:**\n",
        "\n",
        "1. `A person reading a book in a caf√©.`\n",
        "\n",
        "I started with a very basic, generic prompt to see what the model produces when given minimal context.\n",
        "\n",
        "This sets a clear baseline for comparison: What does the model default to in terms of the human subject, scene, and style when no extra detail is provided?\n",
        "\n",
        "2. `A young woman reading a book by the window in a cozy caf√©, warm light, wooden furniture, cup of coffee on the table.`\n",
        "\n",
        "Here, I added simple but important scene elements ‚Äî a window, warm lighting, furniture, and props ‚Äî to test how adding basic descriptive details improves atmosphere, realism, and narrative.\n",
        "\n",
        "3. `A young woman with short hair reading a book by the window in a cozy caf√© during golden hour, warm sunlight streaming in, vintage d√©cor, cup of cappuccino, soft bokeh background, photo-realistic.`\n",
        "\n",
        "\n",
        "This version pushes further by specifying time of day, lighting quality, d√©cor style, and mood, plus a photographic style (photo-realistic). I wanted to see how the AI interprets natural light and depth-of-field cues like bokeh.\n",
        "\n",
        "4. `Portrait of a young woman reading a book by a caf√© window, shot on Canon EOS R5 with 50mm lens at f/1.4, shallow depth of field, golden hour natural light, cinematic mood, soft shadows, high detail.`\n",
        "\n",
        "This prompt demonstrates technical prompt engineering using photography terms: specific camera model, lens, aperture, lighting, and mood. This shows how precise technical details can direct composition, focus, and realism ‚Äî testing the model‚Äôs ability to simulate real-world camera settings.\n",
        "\n",
        "5. `Illustration of a young woman reading a book by a window in a cozy caf√©, warm color palette, soft painterly brushstrokes, storybook art style, calm atmosphere.`\n",
        "\n",
        "Next, I switched the medium entirely to an illustration to test style transfer. Using words like storybook, painterly brushstrokes, and warm color palette shifts the output away from photorealistic and shows how descriptive style words impact artistic feel.\n",
        "\n",
        "6. `A young woman reading a book in a cozy caf√© by the window, warm sunlight, cup of coffee ‚Äî no other people, no pets, no clutter, peaceful clean setting.`\n",
        "\n",
        "This prompt tests negative prompting. By asking for no other people, no pets, no clutter, I explored whether the model can remove distractions and keep the scene focused and minimal.\n",
        "\n",
        "7. `A young woman reading a book by a caf√© window, warm sunlight, cup of coffee, cozy atmosphere, oil painting on canvas, impressionist style, visible brushstrokes, warm earthy colors.`\n",
        "\n",
        "\n",
        "This tests another medium: oil painting in an impressionist style. Here, I wanted to see how words like visible brushstrokes and warm earthy colors create a textured, traditional look compared to digital results.\n",
        "\n",
        "8. `Overhead shot of a young woman reading a book in a cozy caf√©, black-and-white film style, high contrast, dramatic shadows, vintage mood, shot on Leica M6 with 35mm lens, natural light.`\n",
        "\n",
        "\n",
        "This prompt combines an unusual composition (overhead shot) with black-and-white film simulation, vintage camera specs, and dramatic mood. It is to experiment with angle, lighting, and film style.\n",
        "\n",
        "9. `A young woman reading a book in a cozy caf√© by the window, warm golden hour sunlight, cup of coffee, vintage d√©cor ‚Äî no clutter, no background people, no pets, clean minimal scene, peaceful quiet mood.`\n",
        "\n",
        "Finally, I refined the previous negative prompt to show a clean minimal scene with stronger scene control. This tests how combining positive details (golden hour, vintage d√©cor) with negative constraints impacts the output clarity and composition.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0yr3aDyRxVn4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "\n",
        "# Function to generate image based on user_prompt\n",
        "# Returns image url\n",
        "def generate_image(prompt):\n",
        "\n",
        "  response = client.images.generate(\n",
        "        model=\"dall-e-3\",\n",
        "        prompt=prompt,\n",
        "        size=\"1024x1024\",\n",
        "        quality=\"standard\",\n",
        "        n=1\n",
        "    )\n",
        "\n",
        "  return response.data[0].url\n",
        "\n",
        "# Test prompts\n",
        "prompts = [\n",
        "    \"A person reading a book in a caf√©.\",\n",
        "    \"A young woman reading a book by the window in a cozy caf√©, warm light, wooden furniture, cup of coffee on the table.\",\n",
        "    \"A young woman with short hair reading a book by the window in a cozy caf√© during golden hour, warm sunlight streaming in, vintage d√©cor, cup of cappuccino, soft bokeh background, photo-realistic.\",\n",
        "    \"Portrait of a young woman reading a book by a caf√© window, shot on Canon EOS R5 with 50mm lens at f/1.4, shallow depth of field, golden hour natural light, cinematic mood, soft shadows, high detail.\",\n",
        "    \"Illustration of a young woman reading a book by a window in a cozy caf√©, warm color palette, soft painterly brushstrokes, storybook art style, calm atmosphere.\",\n",
        "    \"A young woman reading a book in a cozy caf√© by the window, warm sunlight, cup of coffee ‚Äî no other people, no pets, no clutter, peaceful clean setting.\",\n",
        "    \"A young woman reading a book by a caf√© window, warm sunlight, cup of coffee, cozy atmosphere, oil painting on canvas, impressionist style, visible brushstrokes, warm earthy colors.\",\n",
        "    \"Overhead shot of a young woman reading a book in a cozy caf√©, black-and-white film style, high contrast, dramatic shadows, vintage mood, shot on Leica M6 with 35mm lens, natural light.\",\n",
        "    \"A young woman reading a book in a cozy caf√© by the window, warm golden hour sunlight, cup of coffee, vintage d√©cor ‚Äî no clutter, no background people, no pets, clean minimal scene, peaceful quiet mood.\"\n",
        "]\n",
        "\n",
        "for prompt in prompts:\n",
        "    # response = client.images.generate(\n",
        "    #     model=\"dall-e-3\",\n",
        "    #     prompt=prompt,\n",
        "    #     size=\"1024x1024\",\n",
        "    #     quality=\"standard\",\n",
        "    #     n=1\n",
        "    # )\n",
        "    response = generate_image(prompt)\n",
        "    print(f\"Prompt: {prompt}\")\n",
        "    print(f\"Image URL: {response}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7GHiYvOLp28",
        "outputId": "8d7934ec-82cd-45f9-ba3b-2d1a947102b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prompt: A person reading a book in a caf√©.\n",
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-0PsdThvHk5IFKrJAvuGnQ6Jo/user-Jwg2MoE2vsBQ1YDFXm9GziSs/img-cBVYbjKEh0h9BRWZ0iG85bk5.png?st=2025-07-16T13%3A40%3A26Z&se=2025-07-16T15%3A40%3A26Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-07-15T20%3A26%3A56Z&ske=2025-07-16T20%3A26%3A56Z&sks=b&skv=2024-08-04&sig=NhcrTUGLM8%2BIYvxrjU1d6dv%2BzwiVGdPiBZPwuzUw94o%3D\n",
            "\n",
            "Prompt: A young woman reading a book by the window in a cozy caf√©, warm light, wooden furniture, cup of coffee on the table.\n",
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-0PsdThvHk5IFKrJAvuGnQ6Jo/user-Jwg2MoE2vsBQ1YDFXm9GziSs/img-ojcySsaUQtd0rK43EqiYg0WB.png?st=2025-07-16T13%3A40%3A42Z&se=2025-07-16T15%3A40%3A42Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-07-16T01%3A28%3A30Z&ske=2025-07-17T01%3A28%3A30Z&sks=b&skv=2024-08-04&sig=gUYooRP6H7I0fzLl5uRThSme/fk2E4/Cv13wh5QdLqs%3D\n",
            "\n",
            "Prompt: A young woman with short hair reading a book by the window in a cozy caf√© during golden hour, warm sunlight streaming in, vintage d√©cor, cup of cappuccino, soft bokeh background, photo-realistic.\n",
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-0PsdThvHk5IFKrJAvuGnQ6Jo/user-Jwg2MoE2vsBQ1YDFXm9GziSs/img-PoXMU60LKWmgsz8gDSAPHKC3.png?st=2025-07-16T13%3A40%3A57Z&se=2025-07-16T15%3A40%3A57Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-07-16T04%3A55%3A32Z&ske=2025-07-17T04%3A55%3A32Z&sks=b&skv=2024-08-04&sig=bwaKZd9dL0tyS/e91NqmKdQuqiRPB%2BzPGovDeY/JO7U%3D\n",
            "\n",
            "Prompt: Portrait of a young woman reading a book by a caf√© window, shot on Canon EOS R5 with 50mm lens at f/1.4, shallow depth of field, golden hour natural light, cinematic mood, soft shadows, high detail.\n",
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-0PsdThvHk5IFKrJAvuGnQ6Jo/user-Jwg2MoE2vsBQ1YDFXm9GziSs/img-tkA5cAASsbqAE6Bw57nojd63.png?st=2025-07-16T13%3A41%3A12Z&se=2025-07-16T15%3A41%3A12Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-07-16T14%3A26%3A51Z&ske=2025-07-17T14%3A26%3A51Z&sks=b&skv=2024-08-04&sig=O%2BZES5oKYSatmU5jD5OXeGWqp6FziXa107U1Z/6rkcM%3D\n",
            "\n",
            "Prompt: Illustration of a young woman reading a book by a window in a cozy caf√©, warm color palette, soft painterly brushstrokes, storybook art style, calm atmosphere.\n",
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-0PsdThvHk5IFKrJAvuGnQ6Jo/user-Jwg2MoE2vsBQ1YDFXm9GziSs/img-1VZ9rNBXbTnBjmuLUL1NVMf9.png?st=2025-07-16T13%3A41%3A27Z&se=2025-07-16T15%3A41%3A27Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-07-16T12%3A42%3A52Z&ske=2025-07-17T12%3A42%3A52Z&sks=b&skv=2024-08-04&sig=VGHKIy9EpjZH9QueDHlGxgIUny%2BeFtUmfLpWONNtuAI%3D\n",
            "\n",
            "Prompt: A young woman reading a book in a cozy caf√© by the window, warm sunlight, cup of coffee ‚Äî no other people, no pets, no clutter, peaceful clean setting.\n",
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-0PsdThvHk5IFKrJAvuGnQ6Jo/user-Jwg2MoE2vsBQ1YDFXm9GziSs/img-Le7tTUBId2cd4MQgodsecTCy.png?st=2025-07-16T13%3A41%3A42Z&se=2025-07-16T15%3A41%3A42Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-07-15T19%3A00%3A38Z&ske=2025-07-16T19%3A00%3A38Z&sks=b&skv=2024-08-04&sig=qHJrduLbhj9cP1jNlfHw%2BQDImXJ7JckGm72KBy8f5tE%3D\n",
            "\n",
            "Prompt: A young woman reading a book by a caf√© window, warm sunlight, cup of coffee, cozy atmosphere, oil painting on canvas, impressionist style, visible brushstrokes, warm earthy colors.\n",
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-0PsdThvHk5IFKrJAvuGnQ6Jo/user-Jwg2MoE2vsBQ1YDFXm9GziSs/img-NwIJL5eYxC7fgsT4BDHzuLhV.png?st=2025-07-16T13%3A41%3A54Z&se=2025-07-16T15%3A41%3A54Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-07-16T07%3A09%3A31Z&ske=2025-07-17T07%3A09%3A31Z&sks=b&skv=2024-08-04&sig=nXNs7F4mC%2BDl6p6arXHa0KPzecN6WDfWxxfA4omwxSM%3D\n",
            "\n",
            "Prompt: Overhead shot of a young woman reading a book in a cozy caf√©, black-and-white film style, high contrast, dramatic shadows, vintage mood, shot on Leica M6 with 35mm lens, natural light.\n",
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-0PsdThvHk5IFKrJAvuGnQ6Jo/user-Jwg2MoE2vsBQ1YDFXm9GziSs/img-9tmrMc0Al1Walryd0iJcy48f.png?st=2025-07-16T13%3A42%3A12Z&se=2025-07-16T15%3A42%3A12Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-07-15T22%3A33%3A53Z&ske=2025-07-16T22%3A33%3A53Z&sks=b&skv=2024-08-04&sig=JxswV/cnS8Ai8/tp5BA6JiP0WDTlwhAu3W6NoYLqubk%3D\n",
            "\n",
            "Prompt: A young woman reading a book in a cozy caf√© by the window, warm golden hour sunlight, cup of coffee, vintage d√©cor ‚Äî no clutter, no background people, no pets, clean minimal scene, peaceful quiet mood.\n",
            "Image URL: https://oaidalleapiprodscus.blob.core.windows.net/private/org-0PsdThvHk5IFKrJAvuGnQ6Jo/user-Jwg2MoE2vsBQ1YDFXm9GziSs/img-uhKJeNUUEbg4OYeYS7DyKDQn.png?st=2025-07-16T13%3A42%3A28Z&se=2025-07-16T15%3A42%3A28Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-07-15T17%3A05%3A33Z&ske=2025-07-16T17%3A05%3A33Z&sks=b&skv=2024-08-04&sig=E57pR0wkb960yLzU/drt0bIeRvB69EE2ywFM65p88IY%3D\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A detailed explanation for each image, together with the image itself, is included in the Capstone Report document.\n",
        "\n",
        "However, from all the results combined, the **key general observations** are:\n",
        "\n",
        "1. **Specific details shape realism**: Adding precise technical details ‚Äî such as camera specifications (‚ÄúCanon EOS R5, 50mm lens at f/1.4‚Äù) or lighting conditions (‚Äúgolden hour natural light‚Äù) ‚Äî produces more realistic depth of field, highlights, and shadows. This makes it much easier for the model to replicate the look and feel of real photography when clear, technical cues are included.\n",
        "2. **Diffusion bias on human faces, even with artistic styles**: When art styles like ‚Äúimpressionist style,‚Äù ‚Äúoil painting,‚Äù or ‚Äúvisible brushstrokes‚Äù are used, clear textural changes are visible in the background and props ‚Äî but the human face often remains relatively photorealistic. This is likely because human faces are one of the most overrepresented patterns in training data, so models ‚Äúlearn‚Äù to render them smooth, symmetrical, and well-lit by default. To truly stylize the face, you must explicitly prompt for the artistic effect to apply to the subject‚Äôs facial features too.\n",
        "3. **Negative prompts effectively control distractions**: Instructions such as ‚Äúno clutter,‚Äù ‚Äúno background people,‚Äù and ‚Äúno pets‚Äù are powerful for removing unwanted elements and keeping the scene focused. This shows how prompt engineering can constrain a diffusion model‚Äôs generative ‚Äúautopilot‚Äù and reduce irrelevant filler details.\n",
        "4. **Angle and perspective influence more than just viewpoint**: For example, when the ‚Äúoverhead shot‚Äù angle was specified, the book naturally shifted from the table to the woman‚Äôs lap. This demonstrates that perspective instructions shape not only the camera viewpoint but also the subject‚Äôs pose and the spatial arrangement of props within the scene.\n",
        "5. **Mood descriptors strengthen visual storytelling**: Descriptive phrases like ‚Äúcozy caf√©,‚Äù ‚Äúpeaceful quiet mood,‚Äù and ‚Äúvintage d√©cor‚Äù guide the model‚Äôs choices in colours, props, textures, and light placement. This results in more cohesive and believable compositions.\n",
        "6. **Simple prompts invite default assumptions**: When prompts are vague ‚Äî for example, ‚Äúa person reading a book in a caf√©‚Äù ‚Äî the model tends to fill in common stereotypes, such as adding extra people, coffee cups, or generic cluttered backgrounds. More specific details help steer the output away from these generic defaults and reduce the influence of training data bias.\n",
        "7. **Lack of diversity in subjects**: Throughout these tests, the generated images consistently portrayed the ‚Äúyoung woman‚Äù as fair-skinned, slim, and conventionally attractive, despite no explicit mention of race, body type, or appearance. This highlights the persistence of demographic bias and shows that prompts alone are often insufficient to produce diverse or representative outputs without intentional, explicit instructions.\n",
        "8. **Stylization does not override default identity cues**: Switching to ‚Äústorybook illustration,‚Äù ‚Äúoil painting,‚Äù or ‚Äúvintage vibe‚Äù changes the style of the background and environment, but the woman‚Äôs appearance remains largely the same ‚Äî modern, casual clothing, minimal variation in facial features, and only slight changes in colour palette. This illustrates how strongly the model defaults to familiar, generic identity templates for humans.\n",
        "9. **Order and structure of the prompt matters**: The sequence of words can affect which parts the model focuses on first. Putting subject first, then scene elements, then style or medium, tends to yield more consistent results. Example prompt structure:\n",
        "\n",
        "\n",
        "`[Subject] + [Setting] + [Time of day] + [Lighting] + [Props] + [Mood] + [Style/Medium] + [Technical details] + [Negatives]`\n",
        "\n",
        "\n",
        "**Importance for AI Policy and Regulation**\n",
        "\n",
        "\n",
        "These observations underscore why transparent prompt design, systematic content auditing, and clear documentation are so essential when deploying generative AI tools, especially those capable of creating realistic human representations. Subtle patterns in the training data can easily reinforce stereotypes and cultural defaults without users even realising it. This has direct implications for fairness, accountability, and trust in AI systems.\n",
        "From a governance perspective, it becomes clear that effective AI regulation should address not only how these models are trained and used, but also how the outputs are monitored for bias, representation, and unintended patterns. As more industries adopt generative AI, whether for creative work, communications, or policy support, the need for explainability, diversity-aware prompt engineering, and human oversight will be critical to ensure that AI-generated content reflects real-world values and serves the public good.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y7jGveum7Q2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 5: Weather Agent + Activities Recommendation Agent (using SQL)"
      ],
      "metadata": {
        "id": "yE6CwzCY88_C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1. Weather Agent"
      ],
      "metadata": {
        "id": "eGSIs6V3Ia7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 1) Function: get_weather\n",
        "# --------------------------\n",
        "\n",
        "def get_weather(location):\n",
        "    \"\"\"\n",
        "    Calls the WeatherAPI to get current weather data for the given location.\n",
        "    Handles API errors, invalid keys, invalid locations, timeouts, and unexpected responses.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Build API request\n",
        "        url = \"http://api.weatherapi.com/v1/current.json\"\n",
        "        params = {\n",
        "            \"key\": WEATHER_API_KEY,\n",
        "            \"q\": location,\n",
        "            \"aqi\": \"no\"\n",
        "        }\n",
        "\n",
        "        # Set a timeout to handle slow responses\n",
        "        response = requests.get(url, params=params, timeout=5)\n",
        "        response.raise_for_status()  # Raise exception for bad HTTP codes\n",
        "\n",
        "        data = response.json()\n",
        "\n",
        "        # Check if the response has expected keys\n",
        "        if \"location\" not in data or \"current\" not in data:\n",
        "            raise Exception(\"Unexpected response format from WeatherAPI.\")\n",
        "\n",
        "        return data\n",
        "\n",
        "    except requests.exceptions.Timeout:\n",
        "        raise Exception(\"WeatherAPI request timed out. Please try again later.\")\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        if response.status_code == 401:\n",
        "            raise Exception(\"Invalid WeatherAPI key. Please verify your key in config.py.\")\n",
        "        elif response.status_code == 400:\n",
        "            raise Exception(f\"Invalid location '{location}'. Please check your input.\")\n",
        "        else:\n",
        "            raise Exception(f\"WeatherAPI returned an HTTP error: {str(e)}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        raise Exception(f\"WeatherAPI connection error: {str(e)}\")\n",
        "    except Exception as e:\n",
        "        raise Exception(f\"WeatherAPI error: {str(e)}\")"
      ],
      "metadata": {
        "id": "-e3KExCkDbg6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 2) OpenAI Function Definition\n",
        "# --------------------------\n",
        "\n",
        "# This tells OpenAI about the available function it can call.\n",
        "functions = [\n",
        "    {\n",
        "        \"name\": \"get_weather\",\n",
        "        \"description\": \"Get current weather for a location.\",\n",
        "        \"parameters\": {\n",
        "            \"type\": \"object\",\n",
        "            \"properties\": {\n",
        "                \"location\": {\n",
        "                    \"type\": \"string\",\n",
        "                    \"description\": \"City name or location (e.g., London, Singapore)\"\n",
        "                }\n",
        "            },\n",
        "            \"required\": [\"location\"]\n",
        "        }\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "eEMFDWE3lPdq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------\n",
        "# 3) Main Weather Agent\n",
        "# --------------------------\n",
        "from openai import OpenAI, OpenAIError\n",
        "\n",
        "def weather_agent(user_query):\n",
        "    \"\"\"\n",
        "    Handles a user query by:\n",
        "    1) Sending it to OpenAI.\n",
        "    2) Letting the model decide if it wants to call get_weather.\n",
        "    3) If so, it parses arguments, calls WeatherAPI, and returns formatted weather.\n",
        "    Includes error handling for invalid inputs, missing keys, and network problems.\n",
        "    \"\"\"\n",
        "\n",
        "    client = OpenAI()\n",
        "\n",
        "    try:\n",
        "        # Ask OpenAI if it wants to call the function\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o\",\n",
        "            messages=[{\"role\": \"user\", \"content\": user_query}],\n",
        "            functions=functions,\n",
        "            function_call=\"auto\"\n",
        "        )\n",
        "\n",
        "        # Extract the function call details\n",
        "        function_call = response.choices[0].message.function_call\n",
        "\n",
        "        if function_call and function_call.name == \"get_weather\":\n",
        "            arguments = json.loads(function_call.arguments)\n",
        "\n",
        "            # Ensure 'location' is provided\n",
        "            location = arguments.get(\"location\", \"\").strip()\n",
        "            if not location:\n",
        "                return \"Error: No location provided.\"\n",
        "\n",
        "            # Call WeatherAPI\n",
        "            weather_data = get_weather(location)\n",
        "\n",
        "            # Extract values with fallback\n",
        "            city = weather_data.get('location', {}).get('name', 'Unknown location')\n",
        "            temp_c = weather_data.get('current', {}).get('temp_c', '?')\n",
        "            condition_text = weather_data.get('current', {}).get('condition', {}).get('text', 'Unknown')\n",
        "            humidity = weather_data.get('current', {}).get('humidity', '?')\n",
        "            wind_kph = weather_data.get('current', {}).get('wind_kph', '?')\n",
        "\n",
        "            # Emoji map for weather condition\n",
        "            condition = condition_text.lower()\n",
        "            if (\"sun\" in condition) or (\"clear\" in condition):\n",
        "                emoji = \"‚òÄÔ∏è\"\n",
        "            elif (\"cloud\" in condition) or (\"overcast\" in condition):\n",
        "                emoji = \"‚òÅÔ∏è\"\n",
        "            elif \"rain\" in condition:\n",
        "                emoji = \"üåßÔ∏è\"\n",
        "            elif \"snow\" in condition:\n",
        "                emoji = \"‚ùÑÔ∏è\"\n",
        "            elif \"thunder\" in condition:\n",
        "                emoji = \"üå©Ô∏è\"\n",
        "            else:\n",
        "                emoji = \"üåà\"\n",
        "\n",
        "            # Return multi-line, user-friendly response\n",
        "            return f\"\"\"\\n{emoji} Current weather in {city}:\n",
        "            Temperature: {temp_c}¬∞C\n",
        "            Condition: {condition_text}\n",
        "            Humidity: {humidity}%\n",
        "            Wind: {wind_kph} kph\"\"\"\n",
        "\n",
        "        else:\n",
        "            return \"No matching function was called by OpenAI.\"\n",
        "\n",
        "    except openai.error.AuthenticationError:\n",
        "        return \"Error: Invalid OpenAI API key. Please check your config.py.\"\n",
        "    except openai.error.OpenAIError as e:\n",
        "        return f\"OpenAI API error: {str(e)}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "wXE3t5BMlWWA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2. Recommendation Agent"
      ],
      "metadata": {
        "id": "FA0py-wnIhBz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.1 Recommendation for Museums and Events (Mock)"
      ],
      "metadata": {
        "id": "lQh-Gc8MSmnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mock data - for certain cities only"
      ],
      "metadata": {
        "id": "m7caki0sSs53"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def setup_museums_events_database():\n",
        "    \"\"\"\n",
        "    Creates a 'city_activities.db' SQLite database with two tables:\n",
        "    1) museums\n",
        "    2) events\n",
        "    Each table includes sample indoor/outdoor options for different cities.\n",
        "    \"\"\"\n",
        "\n",
        "    conn = sqlite3.connect('city_activities.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # ---------- Museums Table ----------\n",
        "    c.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS museums (\n",
        "            id INTEGER PRIMARY KEY,\n",
        "            name TEXT,\n",
        "            type TEXT,      -- 'indoor'\n",
        "            description TEXT,\n",
        "            city TEXT,\n",
        "            date TEXT       -- Mock field for consistency\n",
        "        )\n",
        "    ''')\n",
        "\n",
        "    # Clear old rows\n",
        "    c.execute('DELETE FROM museums')\n",
        "\n",
        "    museums = [\n",
        "        # Singapore\n",
        "        ('National Gallery Singapore', 'indoor', 'Southeast Asian art collections', 'Singapore', '2025-07-16'),\n",
        "        ('ArtScience Museum', 'indoor', 'Exhibitions exploring art and tech', 'Singapore', '2025-07-16'),\n",
        "\n",
        "        # London\n",
        "        ('British Museum', 'indoor', 'World history and artefacts', 'London', '2025-07-16'),\n",
        "        ('Tate Modern', 'indoor', 'Modern and contemporary art', 'London', '2025-07-16'),\n",
        "\n",
        "        # New York\n",
        "        ('Metropolitan Museum of Art', 'indoor', 'Extensive art collections from around the world', 'New York', '2025-07-16'),\n",
        "        ('Museum of Modern Art (MoMA)', 'indoor', 'Modern art and design exhibits', 'New York', '2025-07-16'),\n",
        "    ]\n",
        "\n",
        "    c.executemany('INSERT OR IGNORE INTO museums (name, type, description, city, date) VALUES (?,?,?,?,?)', museums)\n",
        "\n",
        "    # ---------- Events Table ----------\n",
        "    c.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS events (\n",
        "            id INTEGER PRIMARY KEY,\n",
        "            name TEXT,\n",
        "            type TEXT,      -- 'indoor' or 'outdoor'\n",
        "            description TEXT,\n",
        "            city TEXT,\n",
        "            date TEXT\n",
        "        )\n",
        "    ''')\n",
        "\n",
        "    # Clear old rows\n",
        "    c.execute('DELETE FROM events')\n",
        "\n",
        "    events = [\n",
        "        # Singapore\n",
        "        ('Marina Bay Sands Light Show', 'outdoor', 'Evening light and water show at Marina Bay', 'Singapore', '2025-07-16'),\n",
        "        ('Esplanade Concert', 'indoor', 'Classical music concert', 'Singapore', '2025-07-16'),\n",
        "\n",
        "        # London\n",
        "        ('Hyde Park Summer Festival', 'outdoor', 'Live music and food stalls', 'London', '2025-07-16'),\n",
        "        ('West End Musical', 'indoor', 'Popular stage musical in the theatre district', 'London', '2025-07-16'),\n",
        "\n",
        "        # New York\n",
        "        ('Central Park Jazz Night', 'outdoor', 'Open-air jazz performance', 'New York', '2025-07-16'),\n",
        "        ('Broadway Play', 'indoor', 'New Broadway theatre production', 'New York', '2025-07-16'),\n",
        "    ]\n",
        "\n",
        "    c.executemany('INSERT OR IGNORE INTO events (name, type, description, city, date) VALUES (?,?,?,?,?)', events)\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    print(\"‚úÖ city_activities.db created with sample museums and events.\")\n",
        "\n",
        "# Run this once to set up the DB\n",
        "if __name__ == \"__main__\":\n",
        "    setup_museums_events_database()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UA8AjotYlpG6",
        "outputId": "83b380f5-2a46-4586-d781-8031328d9e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ city_activities.db created with sample museums and events.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -------------------------------\n",
        "# LOCAL MUSEUMS & EVENTS AGENT\n",
        "# -------------------------------\n",
        "\n",
        "def get_local_activities(city, activity_type):\n",
        "    conn = sqlite3.connect('city_activities.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    museums = []\n",
        "    events = []\n",
        "\n",
        "    # Museums are always indoor\n",
        "    c.execute(\"SELECT name, description FROM museums WHERE city = ?\", (city,))\n",
        "    museums = c.fetchall()\n",
        "\n",
        "    # Events can be indoor or outdoor\n",
        "    c.execute(\"SELECT name, description FROM events WHERE city = ? AND type = ?\", (city, activity_type))\n",
        "    events = c.fetchall()\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    return museums, events\n",
        "\n",
        "def get_sql_tables_local_activities(prompt):\n",
        "    conn = sqlite3.connect('city_activities.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    museums = []\n",
        "    events = []\n",
        "\n",
        "\n",
        "    # Table: Museums\n",
        "    if \"museums\" in prompt:\n",
        "      c.execute(\"SELECT * FROM museums;\")\n",
        "      result = c.fetchall()\n",
        "\n",
        "    # Table: Events\n",
        "    else:\n",
        "      c.execute(\"SELECT * FROM events;\")\n",
        "      result = c.fetchall()\n",
        "\n",
        "    conn.close()\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "tIYiZoz5oZfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_city(prompt):\n",
        "    cities_list = [\"Singapore\", \"London\", \"New York\"]\n",
        "    for city in cities_list:\n",
        "        if city.lower() in prompt.lower():\n",
        "            return city\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_places_recommendation(prompt):\n",
        "\n",
        "  # remove symbols like question mark, that may be attached to the city/activity type in the prompt question\n",
        "  cleaned_prompt = re.sub(r'[^A-Za-z0-9\\s]', '', prompt)\n",
        "\n",
        "  city = extract_city(cleaned_prompt)\n",
        "  activity_type = \"outdoor\" if \"outdoor\" in cleaned_prompt.lower() else \"indoor\"\n",
        "\n",
        "  return get_local_activities(city, activity_type)\n"
      ],
      "metadata": {
        "id": "l9EFRbpfStwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.2. Recommendation for Books (using Google Books API)"
      ],
      "metadata": {
        "id": "3Yj9p3xXSwu9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Google Books API allows us to filter books based on the user's preference of Genre. This function gives the top 3 recommendations of books that the user can choose from."
      ],
      "metadata": {
        "id": "DRMArtq-S3BT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Example of genres that the user can filter the books by:\n",
        "\n",
        "- Science fiction\n",
        "\n",
        "- Fantasy\n",
        "\n",
        "- Horror\n",
        "\n",
        "- Mystery\n",
        "\n",
        "- Romance\n",
        "\n",
        "- Art\n",
        "\n",
        "- Business\n",
        "\n",
        "- History\n",
        "\n",
        "- Self-Help\n",
        "\n",
        "- Computers\n",
        "\n",
        "- Design\n",
        "\n",
        "- Food\n",
        "\n",
        "- Geography\n",
        "\n",
        "- Children\n",
        "\n",
        "- Cooking\n",
        "\n",
        "- Politics\n",
        "\n",
        "- Comedy\n",
        "\n",
        "- Biography\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ul2b05_WTB5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_books_google(genre=None, language=\"en\"):\n",
        "    api_url = \"https://www.googleapis.com/books/v1/volumes\"\n",
        "\n",
        "    # Use the genre directly in the search query\n",
        "    if genre:\n",
        "        query = f\"subject:{genre}\"\n",
        "    else:\n",
        "        query = \"bestseller\" # default genre - pick bestsellers, if the user has not given any input\n",
        "\n",
        "    params = {\n",
        "        \"q\": query,\n",
        "        \"langRestrict\": language,\n",
        "        \"maxResults\": 10\n",
        "    }\n",
        "\n",
        "    response = requests.get(api_url, params=params)\n",
        "    response.raise_for_status()\n",
        "    books = response.json().get(\"items\", [])\n",
        "\n",
        "    # Basic quality filters\n",
        "    filtered_books = []\n",
        "    for book in books:\n",
        "        info = book.get(\"volumeInfo\", {})\n",
        "        page_count = info.get(\"pageCount\", 0)\n",
        "        description = info.get(\"description\", \"\")\n",
        "        avg_rating = info.get(\"averageRating\", 0)\n",
        "\n",
        "        if page_count < 30:\n",
        "            continue\n",
        "        if len(description) < 50:\n",
        "            continue\n",
        "        if avg_rating and avg_rating < 3:\n",
        "            continue\n",
        "\n",
        "        filtered_books.append(info)\n",
        "\n",
        "    if not filtered_books:\n",
        "        return [f\"No suitable books found for genre '{genre}' in language '{language}'. Try a broader term or different genre.\"]\n",
        "\n",
        "    # Output: simple list\n",
        "    results = []\n",
        "    for info in filtered_books[:5]:  # limit to top 5\n",
        "        title = info.get(\"title\", \"No title\")\n",
        "        authors = \", \".join(info.get(\"authors\", [])) if info.get(\"authors\") else \"Unknown Author\"\n",
        "        results.append(f\"{title} by {authors}\")\n",
        "\n",
        "    return results\n"
      ],
      "metadata": {
        "id": "7CFF6YoqWMqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_book_genre(prompt):\n",
        "    known_genres = [\n",
        "        \"science fiction\", \"fantasy\", \"horror\", \"mystery\", \"romance\",\n",
        "        \"art\", \"business\", \"history\", \"self-help\", \"computers\",\n",
        "        \"design\", \"food\", \"geography\", \"children\", \"cooking\", \"politics\"\n",
        "    ]\n",
        "\n",
        "    cleaned_prompt = re.sub(r'[^A-Za-z0-9\\s]', '', prompt)\n",
        "    prompt_lower = cleaned_prompt.lower()\n",
        "\n",
        "    for genre in known_genres:\n",
        "        if genre in prompt_lower:\n",
        "            return genre  # Return the first match found\n",
        "\n",
        "    return None\n",
        "\n",
        "def get_books_recommendation(prompt):\n",
        "\n",
        "  genre = detect_book_genre(prompt)\n",
        "  return recommend_books_google(genre)\n"
      ],
      "metadata": {
        "id": "ldcACCGBVnWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_books_google(genre=\"Science\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkd7c7xM4vhj",
        "outputId": "dba29020-b0a1-43c8-8fab-62586d02df51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The Encyclopedia of Animals by Unknown Author',\n",
              " 'Darwin Among The Machines by George Dyson',\n",
              " 'Industrial Chocolate Manufacture and Use by Steve T. Beckett',\n",
              " \"Life's Devices by Steven Vogel\",\n",
              " 'Whisky by Graham Stewart, Inge Russell']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_books_google(genre=\"Biography\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExFuJK3QQ3Fh",
        "outputId": "017df20b-4657-41f0-c6bb-5cbec8f2f0dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Eat, Pray, Love by Elizabeth Gilbert',\n",
              " 'Einstein by Walter Isaacson',\n",
              " 'Man of Contradictions by Ben Bland',\n",
              " 'What Are the Gospels? by Richard A. Burridge',\n",
              " 'The Lord of Uraniborg by Victor E. Thoren, John Robert Christianson']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.3. Recommendation for Movies (using TMDB API)"
      ],
      "metadata": {
        "id": "Aix_C4WRUX8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Genre ID map for user-friendly input\n",
        "GENRE_ID_MAP = {\n",
        "    \"action\": 28,\n",
        "    \"adventure\": 12,\n",
        "    \"animation\": 16,\n",
        "    \"comedy\": 35,\n",
        "    \"crime\": 80,\n",
        "    \"documentary\": 99,\n",
        "    \"drama\": 18,\n",
        "    \"family\": 10751,\n",
        "    \"fantasy\": 14,\n",
        "    \"history\": 36,\n",
        "    \"horror\": 27,\n",
        "    \"music\": 10402,\n",
        "    \"mystery\": 9648,\n",
        "    \"romance\": 10749,\n",
        "    \"science fiction\": 878,\n",
        "    \"sci-fi\": 878,\n",
        "    \"tv movie\": 10770,\n",
        "    \"thriller\": 53,\n",
        "    \"war\": 10752,\n",
        "    \"western\": 37\n",
        "}\n",
        "\n",
        "\n",
        "def recommend_movies_tmdb(genre=None, language=\"en\", max_results=5):\n",
        "    \"\"\"\n",
        "    Query TMDb API with genre and language filters,\n",
        "    plus quality filters for better results.\n",
        "    \"\"\"\n",
        "    base_url = \"https://api.themoviedb.org/3/discover/movie\"\n",
        "\n",
        "    genre_id = GENRE_ID_MAP.get(genre.lower()) if genre else None\n",
        "\n",
        "    params = {\n",
        "        \"api_key\": TMDB_API_KEY,\n",
        "        \"sort_by\": \"vote_average.desc\",      # Sort by rating instead of raw popularity\n",
        "        \"vote_count.gte\": 50,                # Only movies with 50+ votes\n",
        "        \"vote_average.gte\": 5.5,             # Minimum average rating\n",
        "        \"include_adult\": False,              # Skip adult content\n",
        "        \"language\": language,                # Metadata language\n",
        "        \"with_original_language\": language,  # Original movie language\n",
        "        \"page\": 1\n",
        "    }\n",
        "\n",
        "    if genre_id:\n",
        "        params[\"with_genres\"] = genre_id\n",
        "\n",
        "    try:\n",
        "        response = requests.get(base_url, params=params, timeout=5)\n",
        "        response.raise_for_status()\n",
        "        data = response.json()\n",
        "\n",
        "        if \"results\" not in data or not data[\"results\"]:\n",
        "            return [\"No movies found with these filters.\"]\n",
        "\n",
        "        results = []\n",
        "        for movie in data[\"results\"][:max_results]:\n",
        "            title = movie.get(\"title\", \"Untitled\")\n",
        "            year = movie.get(\"release_date\", \"\")[:4] if movie.get(\"release_date\") else \"N/A\"\n",
        "            # rating = movie.get(\"vote_average\", \"N/A\")\n",
        "            results.append(f\"‚Äò{title}‚Äô ({year})\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    except requests.RequestException as e:\n",
        "        return [f\"Error fetching movies: {str(e)}\"]\n",
        "\n"
      ],
      "metadata": {
        "id": "o3F3SG2sUKGQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_movie_genre(prompt):\n",
        "    known_movie_genres = [\n",
        "        \"action\", \"adventure\", \"animation\", \"comedy\", \"crime\",\n",
        "        \"documentary\", \"drama\", \"family\", \"fantasy\", \"history\",\n",
        "        \"horror\", \"music\", \"mystery\", \"romance\", \"science fiction\",\n",
        "        \"sci-fi\", \"tv movie\", \"thriller\", \"war\", \"western\"\n",
        "    ]\n",
        "\n",
        "    cleaned_prompt = re.sub(r'[^A-Za-z0-9\\s]', '', prompt)\n",
        "    prompt_lower = cleaned_prompt.lower()\n",
        "    for genre in known_movie_genres:\n",
        "        if genre in prompt_lower:\n",
        "            return genre  # Return the first genre found\n",
        "\n",
        "    return None\n",
        "\n",
        "\n",
        "def get_movie_recommendation(prompt):\n",
        "\n",
        "  genre = detect_movie_genre(prompt)\n",
        "  return recommend_movies_tmdb(genre)\n"
      ],
      "metadata": {
        "id": "sQGgeNM6XJ4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_movies_tmdb(genre=\"romance\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DsWu294CUnSn",
        "outputId": "65667758-062b-4dc3-bd9d-29f02edb0491"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['‚Äò¬øQuieres ser mi hijo?‚Äô (2023)',\n",
              " '‚ÄòForrest Gump‚Äô (1994)',\n",
              " \"‚ÄòGabriel's Inferno‚Äô (2020)\",\n",
              " \"‚ÄòGabriel's Inferno: Part II‚Äô (2020)\",\n",
              " \"‚ÄòGabriel's Inferno: Part III‚Äô (2020)\"]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5.2.4. Weather-based recommendation"
      ],
      "metadata": {
        "id": "qnw2rOs9n8M2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_weather_report(user_prompt=\"\"):\n",
        "\n",
        "  weather_summary = weather_agent(user_prompt)\n",
        "  print(weather_summary)"
      ],
      "metadata": {
        "id": "4akht4s8X-Mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simple_weather_report(\"what is the weather in egypt?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1xJcaqqRYJNQ",
        "outputId": "52f5cffe-d6cc-44c5-e1cd-71f9160be41e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚òÄÔ∏è Current weather in Cairo:\n",
            "            Temperature: 39.0¬∞C\n",
            "            Condition: Sunny\n",
            "            Humidity: 9%\n",
            "            Wind: 12.6 kph\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weather_activities_agent(user_prompt=\"\"):\n",
        "    print(\"üå¶Ô∏è Welcome! Let‚Äôs start by checking the weather.\")\n",
        "\n",
        "    # 1) Get weather info\n",
        "    if(len(user_prompt)<1):\n",
        "      location = input(\"Enter your city: \")\n",
        "      weather_summary = weather_agent(f\"What‚Äôs the weather like in {location}?\")\n",
        "      print(weather_summary)\n",
        "\n",
        "    else:\n",
        "      cleaned_prompt = re.sub(r'[^A-Za-z0-9\\s]', '', user_prompt)\n",
        "      weather_summary = weather_agent(cleaned_prompt)\n",
        "      print(weather_summary)\n",
        "      cities_list = [\"Singapore\", \"London\", \"New York\"]\n",
        "      for city in cities_list:\n",
        "          if city.lower() in user_prompt.lower():\n",
        "              location = city\n",
        "              continue\n",
        "\n",
        "    # 2) Ask if user wants recommendations\n",
        "    user_choice = input(\"\\nWould you like activity recommendations based on today‚Äôs weather? (yes/no): \").strip().lower()\n",
        "    if user_choice != \"yes\":\n",
        "        print(\"‚úÖ All done! Have a nice day!\")\n",
        "        return\n",
        "\n",
        "    # 3) Decide activity type\n",
        "    bad_weather_keywords = [\"rain\", \"storm\", \"thunder\", \"cloudy\"]\n",
        "\n",
        "    activity_type = \"indoor\" if any(word in weather_summary.lower() for word in bad_weather_keywords) else \"outdoor\"\n",
        "\n",
        "    print(f\"\\nüí° Based on the weather, I‚Äôll suggest {activity_type} activities.\")\n",
        "\n",
        "    # 4) Get museums & events\n",
        "    museums, events = get_local_activities(location, activity_type)\n",
        "    print(\"\\nüèõÔ∏è Local Museums:\")\n",
        "    if museums:\n",
        "        for m in museums:\n",
        "            print(f\"- {m[0]}: {m[1]}\")\n",
        "    else:\n",
        "        print(\"No museums found found in this city.\")\n",
        "\n",
        "    print(\"\\nüéâ Local Events:\")\n",
        "    if events:\n",
        "        for e in events:\n",
        "            print(f\"- {e[0]}: {e[1]}\")\n",
        "    else:\n",
        "        print(\"No events found in this city.\")\n",
        "\n",
        "    # 5) Books\n",
        "    genre_books = input(\"\\nüìö Do you have a preferred book genre? (leave blank for no filter): \")\n",
        "    books = recommend_books_google(genre=genre_books if genre_books else None)\n",
        "    print(\"\\nüìö Book Recommendations:\")\n",
        "    for b in books:\n",
        "        print(f\"- {b}\")\n",
        "\n",
        "    # 6) Movies\n",
        "    genre_movies = input(\"\\nüé¨ Do you have a preferred movie genre? (leave blank for no filter): \")\n",
        "    movies = recommend_movies_tmdb(genre=genre_movies if genre_movies else None)\n",
        "    print(\"\\nüé¨ Movie Recommendations:\")\n",
        "    for m in movies:\n",
        "        print(f\"- {m}\")\n",
        "\n",
        "\n",
        "\n",
        "    print(\"\\n‚úÖ Done! Enjoy your activities!\")"
      ],
      "metadata": {
        "id": "L_Jr33cQn6fM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weather_activities_agent()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKx8fLNU_TR_",
        "outputId": "c654e7ea-6da2-4e82-f234-e9ec27f67977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üå¶Ô∏è Welcome! Let‚Äôs start by checking the weather.\n",
            "Enter your city: Singapore\n",
            "\n",
            "‚òÅÔ∏è Current weather in Singapore:\n",
            "            Temperature: 29.2¬∞C\n",
            "            Condition: Partly cloudy\n",
            "            Humidity: 79%\n",
            "            Wind: 12.6 kph\n",
            "\n",
            "Would you like activity recommendations based on today‚Äôs weather? (yes/no): yes\n",
            "\n",
            "üí° Based on the weather, I‚Äôll suggest indoor activities.\n",
            "\n",
            "üèõÔ∏è Local Museums:\n",
            "- National Gallery Singapore: Southeast Asian art collections\n",
            "- ArtScience Museum: Exhibitions exploring art and tech\n",
            "\n",
            "üéâ Local Events:\n",
            "- Esplanade Concert: Classical music concert\n",
            "\n",
            "üìö Do you have a preferred book genre? (leave blank for no filter): Math\n",
            "\n",
            "üìö Book Recommendations:\n",
            "- Basic Technical Mathematics with Calculus by Allyn J. Washington\n",
            "- Problem Solving by Richard W. Fisher\n",
            "\n",
            "üé¨ Do you have a preferred movie genre? (leave blank for no filter): Comedy\n",
            "\n",
            "üé¨ Movie Recommendations:\n",
            "- ‚ÄòThe Way to the Heart‚Äô (2024)\n",
            "- ‚ÄòKPop Demon Hunters‚Äô (2025)\n",
            "- ‚Äò¬øQuieres ser mi hijo?‚Äô (2023)\n",
            "- ‚ÄòPulp Fiction‚Äô (1994)\n",
            "- ‚ÄòForrest Gump‚Äô (1994)\n",
            "\n",
            "‚úÖ Done! Enjoy your activities!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Section 6: Smart Multi-Agent Controller"
      ],
      "metadata": {
        "id": "t-69IBuO-44L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Smart Controller\n",
        "# Detects user intent and routes input to the right agent/module\n",
        "\n",
        "def controller(user_input):\n",
        "    prompt = user_input.lower()\n",
        "\n",
        "    if \"weather\" in prompt:\n",
        "      if(\"activities\" in prompt):\n",
        "        return weather_activities_agent(prompt)\n",
        "      else:\n",
        "        return simple_weather_report(prompt)\n",
        "    elif (((\"recommend\" in prompt) and (\"places\" in prompt)) or ((\"suggest\" in prompt) and (\"places\" in prompt))):\n",
        "        return get_places_recommendation(prompt)\n",
        "    elif (((\"recommend\" in prompt) and (\"movies\" in prompt)) or ((\"suggest\" in prompt) and (\"movies\" in prompt))):\n",
        "        return get_movie_recommendation(prompt)\n",
        "    elif (((\"recommend\" in prompt) and (\"books\" in prompt)) or ((\"suggest\" in prompt) and (\"books\" in prompt))):\n",
        "        return get_books_recommendation(prompt)\n",
        "    elif \"image\" in prompt or \"generate\" in prompt or \"draw\" in prompt:\n",
        "        return generate_image(user_input)\n",
        "    elif \"sql\" in prompt:\n",
        "        return get_sql_tables_local_activities(prompt)\n",
        "    elif \"Singapore AI\" in prompt or \"document\" in prompt or \"pdf\" in prompt or \"Singapore AI plan\" or \"Singapore's\" or \"National AI\" in prompt:\n",
        "        return document_q_n_a(user_input)\n",
        "    else:\n",
        "      return memory_chat(user_input)"
      ],
      "metadata": {
        "id": "w9nQw369R9I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def section_break():\n",
        "    print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Test All Capabilities\n",
        "\n",
        "print(\"üß† Memory Chat:\")\n",
        "print(controller(\"Hi, how many continents are there?\"))\n",
        "section_break()\n",
        "\n",
        "print(\"üå§ Simple Weather Info:\")\n",
        "controller(\"What's the weather like in Singapore?\")\n",
        "section_break()\n",
        "\n",
        "print(\"üå§üé≠ Interactive Weather Info:\")\n",
        "controller(\"Recommend activities based on today's weather in New York.\")\n",
        "section_break()\n",
        "\n",
        "print(\"üìö Book Suggestions:\")\n",
        "print(controller(\"Can you recommend some History books?\"))\n",
        "section_break()\n",
        "\n",
        "print(\"üçø Movie Suggestions:\")\n",
        "print(controller(\"Can you recommend some Comedy movies?\"))\n",
        "section_break()\n",
        "\n",
        "print(\"üìä SQL Data:\")\n",
        "print(controller(\"Show me the Museums SQL query.\"))\n",
        "section_break()\n",
        "\n",
        "print(\"üèõÔ∏è Places to visit Suggestions:\")\n",
        "print(controller(\"Can you recommend some places to visit in London?\"))\n",
        "section_break()\n",
        "\n",
        "print(\"üé® Generate an image of a smiling person\")\n",
        "print(controller(\"Generate an image of a smiling person\"))\n",
        "section_break()\n",
        "\n",
        "print(\"üß† Memory Chat:\")\n",
        "print(controller(\"Hi again, what did I ask earlier?\"))\n",
        "\n",
        "print(\"üìÑ Document QA:\")\n",
        "print(controller(\"What is Singapore's National AI Strategy 2.0?\"))\n",
        "section_break()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r66ddK8DATV3",
        "outputId": "1c89fbe9-eb60-4efd-a3f8-0322402498d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† Memory Chat:\n",
            "There are seven continents: Africa, Antarctica, Asia, Europe, North America, Australia (Oceania), and South America.\n",
            "\n",
            "==================================================\n",
            "üå§ Simple Weather Info:\n",
            "\n",
            "‚òÅÔ∏è Current weather in Singapore:\n",
            "            Temperature: 29.2¬∞C\n",
            "            Condition: Partly cloudy\n",
            "            Humidity: 79%\n",
            "            Wind: 12.6 kph\n",
            "\n",
            "==================================================\n",
            "üå§üé≠ Interactive Weather Info:\n",
            "üå¶Ô∏è Welcome! Let‚Äôs start by checking the weather.\n",
            "\n",
            "‚òÅÔ∏è Current weather in New York:\n",
            "            Temperature: 28.9¬∞C\n",
            "            Condition: Overcast\n",
            "            Humidity: 65%\n",
            "            Wind: 9.4 kph\n",
            "\n",
            "Would you like activity recommendations based on today‚Äôs weather? (yes/no): yes\n",
            "\n",
            "üí° Based on the weather, I‚Äôll suggest outdoor activities.\n",
            "\n",
            "üèõÔ∏è Local Museums:\n",
            "- Metropolitan Museum of Art: Extensive art collections from around the world\n",
            "- Museum of Modern Art (MoMA): Modern art and design exhibits\n",
            "\n",
            "üéâ Local Events:\n",
            "- Central Park Jazz Night: Open-air jazz performance\n",
            "\n",
            "üìö Do you have a preferred book genre? (leave blank for no filter): History\n",
            "\n",
            "üìö Book Recommendations:\n",
            "- Singapore Burning by Colin Smith\n",
            "- The Discarded Image by C. S. Lewis\n",
            "- Undoing Gender by Judith Butler\n",
            "- METEOROLOGY by Aristotle\n",
            "- Tibet by Sam van Schaik\n",
            "\n",
            "üé¨ Do you have a preferred movie genre? (leave blank for no filter): Drama\n",
            "\n",
            "üé¨ Movie Recommendations:\n",
            "- ‚ÄòThe Way to the Heart‚Äô (2024)\n",
            "- ‚ÄòThe Shawshank Redemption‚Äô (1994)\n",
            "- ‚ÄòThe Godfather‚Äô (1972)\n",
            "- ‚ÄòSquare One‚Äô (2019)\n",
            "- ‚ÄòThe King of Kings‚Äô (2025)\n",
            "\n",
            "‚úÖ Done! Enjoy your activities!\n",
            "\n",
            "==================================================\n",
            "üìö Book Suggestions:\n",
            "['Singapore Burning by Colin Smith', 'The Discarded Image by C. S. Lewis', 'Undoing Gender by Judith Butler', 'METEOROLOGY by Aristotle', 'Tibet by Sam van Schaik']\n",
            "\n",
            "==================================================\n",
            "üçø Movie Suggestions:\n",
            "['‚ÄòThe Way to the Heart‚Äô (2024)', '‚ÄòKPop Demon Hunters‚Äô (2025)', '‚Äò¬øQuieres ser mi hijo?‚Äô (2023)', '‚ÄòPulp Fiction‚Äô (1994)', '‚ÄòForrest Gump‚Äô (1994)']\n",
            "\n",
            "==================================================\n",
            "üìä SQL Data:\n",
            "[(1, 'National Gallery Singapore', 'indoor', 'Southeast Asian art collections', 'Singapore', '2025-07-16'), (2, 'ArtScience Museum', 'indoor', 'Exhibitions exploring art and tech', 'Singapore', '2025-07-16'), (3, 'British Museum', 'indoor', 'World history and artefacts', 'London', '2025-07-16'), (4, 'Tate Modern', 'indoor', 'Modern and contemporary art', 'London', '2025-07-16'), (5, 'Metropolitan Museum of Art', 'indoor', 'Extensive art collections from around the world', 'New York', '2025-07-16'), (6, 'Museum of Modern Art (MoMA)', 'indoor', 'Modern art and design exhibits', 'New York', '2025-07-16')]\n",
            "\n",
            "==================================================\n",
            "üèõÔ∏è Places to visit Suggestions:\n",
            "([('British Museum', 'World history and artefacts'), ('Tate Modern', 'Modern and contemporary art')], [('West End Musical', 'Popular stage musical in the theatre district')])\n",
            "\n",
            "==================================================\n",
            "üé® Generate an image of a smiling person\n",
            "https://oaidalleapiprodscus.blob.core.windows.net/private/org-0PsdThvHk5IFKrJAvuGnQ6Jo/user-Jwg2MoE2vsBQ1YDFXm9GziSs/img-966SdihuYK0mYYVQ4c1t0tQ3.png?st=2025-07-16T13%3A44%3A03Z&se=2025-07-16T15%3A44%3A03Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=475fd488-6c59-44a5-9aa9-31c4db451bea&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-07-16T13%3A36%3A31Z&ske=2025-07-17T13%3A36%3A31Z&sks=b&skv=2024-08-04&sig=lMlafmyG1yrX2iL7oc/BxsyhArL0hkotwVfiN7rIXcw%3D\n",
            "\n",
            "==================================================\n",
            "üß† Memory Chat:\n",
            "I'm an AI assistant and I don't ask questions. If you have any questions or need assistance, feel free to ask, and I'll do my best to help you.\n",
            "üìÑ Document QA:\n",
            "Singapore's National AI Strategy 2.0, also known as NAIS 2.0, is a strategic plan developed to harness AI for the public good, not only for Singapore but also for the world. It aims to address global challenges like population health and climate change, uplift and empower people and businesses for an AI-enabled future, and achieve twin goals of excellence in AI development. The strategy involves moving beyond flagship National AI Projects, taking a systems approach by collaborating with stakeholders within and outside Singapore to accelerate the exchange of ideas and administer AI-enabled solutions at scale.\n",
            "\n",
            "==================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Conclusion"
      ],
      "metadata": {
        "id": "eC_z0hvJ6uhP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This multi-agent AI assistant system successfully demonstrates the integration of seven distinct AI capabilities through a unified controller architecture. The implementation showcases practical applications of current AI technologies while maintaining system modularity and user-friendly interaction patterns.\n",
        "\n",
        "\n",
        "**Key Technical Contributions**\n",
        "* Smart Controller: Intelligent intent recognition and routing\n",
        "* Memory Integration: Consistent context across different agents\n",
        "* Multi-Modal Capabilities: Text, image, and data processing\n",
        "* External API Coordination: Robust integration with multiple services\n",
        "\n",
        "\n",
        "**System Strengths**\n",
        "* Comprehensive Functionality: Covers diverse AI use cases\n",
        "* Modular Design: Easy to extend and modify\n",
        "* Robust Architecture: Handles failures gracefully\n",
        "* User-Friendly Interface: Natural language interaction\n",
        "\n",
        "\n",
        "The system demonstrates how modern AI technologies can be effectively combined to create sophisticated, multi-functional AI assistants that maintain coherent user experiences across diverse capabilities."
      ],
      "metadata": {
        "id": "R997v7aE61iN"
      }
    }
  ]
}